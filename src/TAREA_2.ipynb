{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKzE3UlOKBm2"
      },
      "source": [
        "\n",
        "## PARTE A: \n",
        "#### Binary Logistic Regression from Scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "un5fUpKTKYLN"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Logistic Regression from Scratch: Binary, OvA, and Softmax\n",
        "# ============================================================\n",
        "\n",
        "!pip -q install ucimlrepo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "np.random.seed(42)\n",
        "RANDOM_STATE = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Lvk7x18MK8sD"
      },
      "outputs": [],
      "source": [
        "heart_disease = fetch_ucirepo(id = 45)\n",
        "X = heart_disease.data.features \n",
        "Y = heart_disease.data.targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 838
        },
        "id": "fuzwe5E3K8yD",
        "outputId": "1938b9f7-a426-4a65-bb30-c8fecc100e73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>role</th>\n",
              "      <th>type</th>\n",
              "      <th>demographic</th>\n",
              "      <th>description</th>\n",
              "      <th>units</th>\n",
              "      <th>missing_values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>age</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>Age</td>\n",
              "      <td>None</td>\n",
              "      <td>years</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sex</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>Sex</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cp</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trestbps</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>resting blood pressure (on admission to the ho...</td>\n",
              "      <td>mm Hg</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chol</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>serum cholestoral</td>\n",
              "      <td>mg/dl</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>fbs</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>fasting blood sugar &gt; 120 mg/dl</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>restecg</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>thalach</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>maximum heart rate achieved</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>exang</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>exercise induced angina</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>oldpeak</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>ST depression induced by exercise relative to ...</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>slope</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>ca</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>number of major vessels (0-3) colored by flour...</td>\n",
              "      <td>None</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>thal</td>\n",
              "      <td>Feature</td>\n",
              "      <td>Categorical</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>num</td>\n",
              "      <td>Target</td>\n",
              "      <td>Integer</td>\n",
              "      <td>None</td>\n",
              "      <td>diagnosis of heart disease</td>\n",
              "      <td>None</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        name     role         type demographic  \\\n",
              "0        age  Feature      Integer         Age   \n",
              "1        sex  Feature  Categorical         Sex   \n",
              "2         cp  Feature  Categorical        None   \n",
              "3   trestbps  Feature      Integer        None   \n",
              "4       chol  Feature      Integer        None   \n",
              "5        fbs  Feature  Categorical        None   \n",
              "6    restecg  Feature  Categorical        None   \n",
              "7    thalach  Feature      Integer        None   \n",
              "8      exang  Feature  Categorical        None   \n",
              "9    oldpeak  Feature      Integer        None   \n",
              "10     slope  Feature  Categorical        None   \n",
              "11        ca  Feature      Integer        None   \n",
              "12      thal  Feature  Categorical        None   \n",
              "13       num   Target      Integer        None   \n",
              "\n",
              "                                          description  units missing_values  \n",
              "0                                                None  years             no  \n",
              "1                                                None   None             no  \n",
              "2                                                None   None             no  \n",
              "3   resting blood pressure (on admission to the ho...  mm Hg             no  \n",
              "4                                   serum cholestoral  mg/dl             no  \n",
              "5                     fasting blood sugar > 120 mg/dl   None             no  \n",
              "6                                                None   None             no  \n",
              "7                         maximum heart rate achieved   None             no  \n",
              "8                             exercise induced angina   None             no  \n",
              "9   ST depression induced by exercise relative to ...   None             no  \n",
              "10                                               None   None             no  \n",
              "11  number of major vessels (0-3) colored by flour...   None            yes  \n",
              "12                                               None   None            yes  \n",
              "13                         diagnosis of heart disease   None             no  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heart_disease.variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resumen de valores nulos por columna:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>variable</th>\n",
              "      <th>nulos</th>\n",
              "      <th>porcentaje_nulos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ca</td>\n",
              "      <td>4</td>\n",
              "      <td>1.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>thal</td>\n",
              "      <td>2</td>\n",
              "      <td>0.66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>age</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sex</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>cp</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>trestbps</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>chol</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>fbs</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>restecg</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>thalach</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>exang</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>oldpeak</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>slope</td>\n",
              "      <td>0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    variable  nulos  porcentaje_nulos\n",
              "0         ca      4              1.32\n",
              "1       thal      2              0.66\n",
              "2        age      0              0.00\n",
              "3        sex      0              0.00\n",
              "4         cp      0              0.00\n",
              "5   trestbps      0              0.00\n",
              "6       chol      0              0.00\n",
              "7        fbs      0              0.00\n",
              "8    restecg      0              0.00\n",
              "9    thalach      0              0.00\n",
              "10     exang      0              0.00\n",
              "11   oldpeak      0              0.00\n",
              "12     slope      0              0.00"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Hallamo el numero de valores faltantes\n",
        "null_stats = []\n",
        "\n",
        "for col in X.columns:\n",
        "    total_nulls = X[col].isnull().sum()\n",
        "    percent_nulls = (total_nulls / len(X)) * 100\n",
        "    null_stats.append({\n",
        "        'variable': col,\n",
        "        'nulos': total_nulls,\n",
        "        'porcentaje_nulos': round(percent_nulls, 2)\n",
        "    })\n",
        "\n",
        "null_summary = pd.DataFrame(null_stats)\n",
        "\n",
        "null_summary = null_summary.sort_values(by='porcentaje_nulos', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"Resumen de valores nulos por columna:\")\n",
        "display(null_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cURNq99gLx48"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age         0\n",
              "sex         0\n",
              "cp          0\n",
              "trestbps    0\n",
              "chol        0\n",
              "fbs         0\n",
              "restecg     0\n",
              "thalach     0\n",
              "exang       0\n",
              "oldpeak     0\n",
              "slope       0\n",
              "ca          0\n",
              "thal        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Reemplazando missing values con la mediana\n",
        "X = X.fillna(X.median())\n",
        "X.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "MGbhtaj9L4Mq",
        "outputId": "4a7e05ef-d3cb-42e2-a51e-89c46275b8f5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num\n",
              "0    0\n",
              "1    2\n",
              "2    1\n",
              "3    0\n",
              "4    0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.isna().sum()\n",
        "Y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "W91xeAJbL7uG",
        "outputId": "998d1429-b05b-4dce-ad67-20dadf9c3b18"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   num\n",
              "0    0\n",
              "1    2\n",
              "2    1\n",
              "3    0\n",
              "4    0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertimos  etiquetas mayores a 0 en 1, el resto en 0\n",
        "Y = pd.DataFrame(np.where(Y > 0, 1, 0), columns=Y.columns) \n",
        "Y = Y.values.ravel()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(303,)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    0.0\n",
            "1    3.0\n",
            "2    2.0\n",
            "3    0.0\n",
            "4    0.0\n",
            "Name: ca, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(X['ca'].head())\n",
        "# a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pN1hlCsEM0JC",
        "outputId": "0a0ce2c6-9cec-4144-b84c-e2543893f2cc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    0.0\n",
            "1    3.0\n",
            "2    2.0\n",
            "3    0.0\n",
            "4    0.0\n",
            "Name: ca, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Ver primeras filas de la variable\n",
        "print(X['ca'].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Se aplica One-Hot Encoding para transformar las variables categóricas, \n",
        "# ya que no existe un orden intrínseco entre sus categorías.\n",
        "categorical_cols = [\"sex\", \"cp\", \"fbs\", \"restecg\", \"exang\", \"slope\", \"ca\", \"thal\"]\n",
        "X_encoded = pd.get_dummies(data=X, columns=categorical_cols)\n",
        "\n",
        "X_encoded.insert(0, \"Intercepto\", 1.0)\n",
        "\n",
        "X_encoded = X_encoded.apply(pd.to_numeric, downcast='float')\n",
        "X_encoded = X_encoded.astype('float64')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Intercepto</th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>sex_0</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>...</th>\n",
              "      <th>slope_1</th>\n",
              "      <th>slope_2</th>\n",
              "      <th>slope_3</th>\n",
              "      <th>ca_0.0</th>\n",
              "      <th>ca_1.0</th>\n",
              "      <th>ca_2.0</th>\n",
              "      <th>ca_3.0</th>\n",
              "      <th>thal_3.0</th>\n",
              "      <th>thal_6.0</th>\n",
              "      <th>thal_7.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>1.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>264.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>1.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>144.0</td>\n",
              "      <td>193.0</td>\n",
              "      <td>141.0</td>\n",
              "      <td>3.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>1.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>131.0</td>\n",
              "      <td>115.0</td>\n",
              "      <td>1.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>1.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>236.0</td>\n",
              "      <td>174.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>1.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>138.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>173.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>303 rows × 29 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Intercepto   age  trestbps   chol  thalach  oldpeak  sex_0  sex_1  cp_1  \\\n",
              "0           1.0  63.0     145.0  233.0    150.0      2.3    0.0    1.0   1.0   \n",
              "1           1.0  67.0     160.0  286.0    108.0      1.5    0.0    1.0   0.0   \n",
              "2           1.0  67.0     120.0  229.0    129.0      2.6    0.0    1.0   0.0   \n",
              "3           1.0  37.0     130.0  250.0    187.0      3.5    0.0    1.0   0.0   \n",
              "4           1.0  41.0     130.0  204.0    172.0      1.4    1.0    0.0   0.0   \n",
              "..          ...   ...       ...    ...      ...      ...    ...    ...   ...   \n",
              "298         1.0  45.0     110.0  264.0    132.0      1.2    0.0    1.0   1.0   \n",
              "299         1.0  68.0     144.0  193.0    141.0      3.4    0.0    1.0   0.0   \n",
              "300         1.0  57.0     130.0  131.0    115.0      1.2    0.0    1.0   0.0   \n",
              "301         1.0  57.0     130.0  236.0    174.0      0.0    1.0    0.0   0.0   \n",
              "302         1.0  38.0     138.0  175.0    173.0      0.0    0.0    1.0   0.0   \n",
              "\n",
              "     cp_2  ...  slope_1  slope_2  slope_3  ca_0.0  ca_1.0  ca_2.0  ca_3.0  \\\n",
              "0     0.0  ...      0.0      0.0      1.0     1.0     0.0     0.0     0.0   \n",
              "1     0.0  ...      0.0      1.0      0.0     0.0     0.0     0.0     1.0   \n",
              "2     0.0  ...      0.0      1.0      0.0     0.0     0.0     1.0     0.0   \n",
              "3     0.0  ...      0.0      0.0      1.0     1.0     0.0     0.0     0.0   \n",
              "4     1.0  ...      1.0      0.0      0.0     1.0     0.0     0.0     0.0   \n",
              "..    ...  ...      ...      ...      ...     ...     ...     ...     ...   \n",
              "298   0.0  ...      0.0      1.0      0.0     1.0     0.0     0.0     0.0   \n",
              "299   0.0  ...      0.0      1.0      0.0     0.0     0.0     1.0     0.0   \n",
              "300   0.0  ...      0.0      1.0      0.0     0.0     1.0     0.0     0.0   \n",
              "301   1.0  ...      0.0      1.0      0.0     0.0     1.0     0.0     0.0   \n",
              "302   0.0  ...      1.0      0.0      0.0     0.0     0.0     0.0     0.0   \n",
              "\n",
              "     thal_3.0  thal_6.0  thal_7.0  \n",
              "0         0.0       1.0       0.0  \n",
              "1         1.0       0.0       0.0  \n",
              "2         0.0       0.0       1.0  \n",
              "3         1.0       0.0       0.0  \n",
              "4         1.0       0.0       0.0  \n",
              "..        ...       ...       ...  \n",
              "298       0.0       0.0       1.0  \n",
              "299       0.0       0.0       1.0  \n",
              "300       0.0       0.0       1.0  \n",
              "301       1.0       0.0       0.0  \n",
              "302       1.0       0.0       0.0  \n",
              "\n",
              "[303 rows x 29 columns]"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_encoded,  \n",
        "    Y,          \n",
        "    train_size=0.7,\n",
        "    shuffle=True,\n",
        "    random_state=5102025\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(212, 29)"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(212,)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalización de variables numéricas\n",
        "columnas_numericas = [\"age\", \"trestbps\", \"chol\", \"thalach\", \"oldpeak\"]\n",
        "\n",
        "media_train = X_train[columnas_numericas].mean()\n",
        "desviacion_train = X_train[columnas_numericas].std()\n",
        "\n",
        "X_train.loc[:, columnas_numericas] = (X_train[columnas_numericas] - media_train) / desviacion_train\n",
        "X_test.loc[:, columnas_numericas] = (X_test[columnas_numericas] - media_train) / desviacion_train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 212 entries, 139 to 50\n",
            "Data columns (total 29 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   Intercepto  212 non-null    float64\n",
            " 1   age         212 non-null    float64\n",
            " 2   trestbps    212 non-null    float64\n",
            " 3   chol        212 non-null    float64\n",
            " 4   thalach     212 non-null    float64\n",
            " 5   oldpeak     212 non-null    float64\n",
            " 6   sex_0       212 non-null    float64\n",
            " 7   sex_1       212 non-null    float64\n",
            " 8   cp_1        212 non-null    float64\n",
            " 9   cp_2        212 non-null    float64\n",
            " 10  cp_3        212 non-null    float64\n",
            " 11  cp_4        212 non-null    float64\n",
            " 12  fbs_0       212 non-null    float64\n",
            " 13  fbs_1       212 non-null    float64\n",
            " 14  restecg_0   212 non-null    float64\n",
            " 15  restecg_1   212 non-null    float64\n",
            " 16  restecg_2   212 non-null    float64\n",
            " 17  exang_0     212 non-null    float64\n",
            " 18  exang_1     212 non-null    float64\n",
            " 19  slope_1     212 non-null    float64\n",
            " 20  slope_2     212 non-null    float64\n",
            " 21  slope_3     212 non-null    float64\n",
            " 22  ca_0.0      212 non-null    float64\n",
            " 23  ca_1.0      212 non-null    float64\n",
            " 24  ca_2.0      212 non-null    float64\n",
            " 25  ca_3.0      212 non-null    float64\n",
            " 26  thal_3.0    212 non-null    float64\n",
            " 27  thal_6.0    212 non-null    float64\n",
            " 28  thal_7.0    212 non-null    float64\n",
            "dtypes: float64(29)\n",
            "memory usage: 49.7 KB\n"
          ]
        }
      ],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dLfqu5QN1c0"
      },
      "source": [
        "2. Model Derivation and Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Calculamos la probabilidad predicha, la log-verosimilitud y su gradiente en regresión logística.\n",
        "\n",
        "def sigmoid_func(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def predict_prob(X, weights):\n",
        "    \"\"\"Calcula la probabilidad predicha para datos X con parámetros weights.\"\"\"\n",
        "    return sigmoid_func(np.dot(X, weights))\n",
        "\n",
        "def compute_log_likelihood(weights, X, y):\n",
        "    \"\"\"Calcula la log-verosimilitud media con suavizado numérico para evitar log(0).\"\"\"\n",
        "    preds = predict_prob(X, weights)\n",
        "    epsilon = 1e-6\n",
        "    return np.mean(y * np.log(preds + epsilon) + (1 - y) * np.log(1 - preds + epsilon))\n",
        "\n",
        "def compute_gradient(weights, X, y):\n",
        "    \"\"\"Calcula el gradiente de la log-verosimilitud para la regresión logística.\"\"\"\n",
        "    preds = predict_prob(X, weights)\n",
        "    \n",
        "    return np.mean((preds - y)[:, np.newaxis] * X, axis=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Creamos las clases que implementa regresión logística mediante descenso de gradiente con seguimiento de convergencia.\n",
        "class LogisticGradientDescent:\n",
        "    def __init__(self, learning_rate, X_train, y_train, tol=1e-5):\n",
        "        self.lr = learning_rate\n",
        "        self.X = np.array(X_train)\n",
        "        self.y = np.array(y_train)\n",
        "        self.tolerance = tol\n",
        "        self.theta = np.zeros(self.X.shape[1])\n",
        "        self.theta_old = np.ones(self.X.shape[1]) * np.inf  # Valor inicial para evitar corte prematuro\n",
        "        self.iteration = 0\n",
        "        self.loss_history = []\n",
        "        self.coefficients = None\n",
        "\n",
        "    def fit(self):\n",
        "        print(f\"===== Entrenando con learning rate = {self.lr:.4f} =====\")\n",
        "        while np.linalg.norm(self.theta - self.theta_old) > self.tolerance:\n",
        "            current_loss = compute_log_likelihood(self.theta, self.X, self.y)\n",
        "            self.loss_history.append(current_loss)\n",
        "\n",
        "            if self.iteration % 500 == 0:\n",
        "                print(f\"Iteración {self.iteration}: Log-verosimilitud = {current_loss:.6f}\")\n",
        "\n",
        "            self.theta_old = self.theta.copy()\n",
        "            grad = compute_gradient(self.theta, self.X, self.y)\n",
        "            self.theta = self.theta_old - self.lr * grad\n",
        "            self.iteration += 1\n",
        "\n",
        "        self.coefficients = self.theta.copy()\n",
        "        print(f\"\\nCoeficientes finales:\\n{self.coefficients}\")\n",
        "        print(f\"Número total de iteraciones: {self.iteration}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Entrenando con learning rate = 0.1000 =====\n",
            "Iteración 0: Log-verosimilitud = -0.693145\n",
            "Iteración 500: Log-verosimilitud = -0.324531\n",
            "Iteración 1000: Log-verosimilitud = -0.316345\n",
            "Iteración 1500: Log-verosimilitud = -0.313732\n",
            "Iteración 2000: Log-verosimilitud = -0.312568\n",
            "Iteración 2500: Log-verosimilitud = -0.311939\n",
            "Iteración 3000: Log-verosimilitud = -0.311546\n",
            "Iteración 3500: Log-verosimilitud = -0.311270\n",
            "Iteración 4000: Log-verosimilitud = -0.311058\n",
            "Iteración 4500: Log-verosimilitud = -0.310883\n",
            "Iteración 5000: Log-verosimilitud = -0.310733\n",
            "Iteración 5500: Log-verosimilitud = -0.310599\n",
            "Iteración 6000: Log-verosimilitud = -0.310477\n",
            "Iteración 6500: Log-verosimilitud = -0.310363\n",
            "Iteración 7000: Log-verosimilitud = -0.310258\n",
            "Iteración 7500: Log-verosimilitud = -0.310158\n",
            "Iteración 8000: Log-verosimilitud = -0.310063\n",
            "Iteración 8500: Log-verosimilitud = -0.309972\n",
            "Iteración 9000: Log-verosimilitud = -0.309886\n",
            "Iteración 9500: Log-verosimilitud = -0.309803\n",
            "Iteración 10000: Log-verosimilitud = -0.309723\n",
            "Iteración 10500: Log-verosimilitud = -0.309646\n",
            "Iteración 11000: Log-verosimilitud = -0.309572\n",
            "Iteración 11500: Log-verosimilitud = -0.309501\n",
            "Iteración 12000: Log-verosimilitud = -0.309432\n",
            "Iteración 12500: Log-verosimilitud = -0.309366\n",
            "Iteración 13000: Log-verosimilitud = -0.309302\n",
            "Iteración 13500: Log-verosimilitud = -0.309240\n",
            "Iteración 14000: Log-verosimilitud = -0.309180\n",
            "Iteración 14500: Log-verosimilitud = -0.309121\n",
            "Iteración 15000: Log-verosimilitud = -0.309065\n",
            "Iteración 15500: Log-verosimilitud = -0.309011\n",
            "Iteración 16000: Log-verosimilitud = -0.308958\n",
            "Iteración 16500: Log-verosimilitud = -0.308906\n",
            "Iteración 17000: Log-verosimilitud = -0.308856\n",
            "Iteración 17500: Log-verosimilitud = -0.308808\n",
            "Iteración 18000: Log-verosimilitud = -0.308761\n",
            "Iteración 18500: Log-verosimilitud = -0.308715\n",
            "Iteración 19000: Log-verosimilitud = -0.308671\n",
            "Iteración 19500: Log-verosimilitud = -0.308628\n",
            "Iteración 20000: Log-verosimilitud = -0.308586\n",
            "Iteración 20500: Log-verosimilitud = -0.308545\n",
            "Iteración 21000: Log-verosimilitud = -0.308505\n",
            "Iteración 21500: Log-verosimilitud = -0.308467\n",
            "Iteración 22000: Log-verosimilitud = -0.308429\n",
            "Iteración 22500: Log-verosimilitud = -0.308392\n",
            "Iteración 23000: Log-verosimilitud = -0.308357\n",
            "Iteración 23500: Log-verosimilitud = -0.308322\n",
            "Iteración 24000: Log-verosimilitud = -0.308288\n",
            "Iteración 24500: Log-verosimilitud = -0.308255\n",
            "Iteración 25000: Log-verosimilitud = -0.308222\n",
            "Iteración 25500: Log-verosimilitud = -0.308191\n",
            "Iteración 26000: Log-verosimilitud = -0.308160\n",
            "Iteración 26500: Log-verosimilitud = -0.308130\n",
            "Iteración 27000: Log-verosimilitud = -0.308100\n",
            "Iteración 27500: Log-verosimilitud = -0.308072\n",
            "Iteración 28000: Log-verosimilitud = -0.308043\n",
            "Iteración 28500: Log-verosimilitud = -0.308016\n",
            "Iteración 29000: Log-verosimilitud = -0.307989\n",
            "Iteración 29500: Log-verosimilitud = -0.307963\n",
            "Iteración 30000: Log-verosimilitud = -0.307937\n",
            "Iteración 30500: Log-verosimilitud = -0.307912\n",
            "Iteración 31000: Log-verosimilitud = -0.307888\n",
            "Iteración 31500: Log-verosimilitud = -0.307864\n",
            "Iteración 32000: Log-verosimilitud = -0.307840\n",
            "Iteración 32500: Log-verosimilitud = -0.307817\n",
            "Iteración 33000: Log-verosimilitud = -0.307795\n",
            "Iteración 33500: Log-verosimilitud = -0.307773\n",
            "Iteración 34000: Log-verosimilitud = -0.307751\n",
            "Iteración 34500: Log-verosimilitud = -0.307730\n",
            "Iteración 35000: Log-verosimilitud = -0.307709\n",
            "Iteración 35500: Log-verosimilitud = -0.307689\n",
            "Iteración 36000: Log-verosimilitud = -0.307669\n",
            "Iteración 36500: Log-verosimilitud = -0.307649\n",
            "Iteración 37000: Log-verosimilitud = -0.307630\n",
            "Iteración 37500: Log-verosimilitud = -0.307611\n",
            "Iteración 38000: Log-verosimilitud = -0.307593\n",
            "Iteración 38500: Log-verosimilitud = -0.307575\n",
            "Iteración 39000: Log-verosimilitud = -0.307557\n",
            "Iteración 39500: Log-verosimilitud = -0.307539\n",
            "Iteración 40000: Log-verosimilitud = -0.307522\n",
            "Iteración 40500: Log-verosimilitud = -0.307505\n",
            "Iteración 41000: Log-verosimilitud = -0.307489\n",
            "Iteración 41500: Log-verosimilitud = -0.307473\n",
            "Iteración 42000: Log-verosimilitud = -0.307457\n",
            "Iteración 42500: Log-verosimilitud = -0.307441\n",
            "Iteración 43000: Log-verosimilitud = -0.307426\n",
            "Iteración 43500: Log-verosimilitud = -0.307411\n",
            "Iteración 44000: Log-verosimilitud = -0.307396\n",
            "Iteración 44500: Log-verosimilitud = -0.307381\n",
            "Iteración 45000: Log-verosimilitud = -0.307367\n",
            "Iteración 45500: Log-verosimilitud = -0.307353\n",
            "Iteración 46000: Log-verosimilitud = -0.307339\n",
            "Iteración 46500: Log-verosimilitud = -0.307325\n",
            "Iteración 47000: Log-verosimilitud = -0.307312\n",
            "Iteración 47500: Log-verosimilitud = -0.307299\n",
            "Iteración 48000: Log-verosimilitud = -0.307286\n",
            "Iteración 48500: Log-verosimilitud = -0.307273\n",
            "Iteración 49000: Log-verosimilitud = -0.307260\n",
            "Iteración 49500: Log-verosimilitud = -0.307248\n",
            "Iteración 50000: Log-verosimilitud = -0.307236\n",
            "Iteración 50500: Log-verosimilitud = -0.307224\n",
            "Iteración 51000: Log-verosimilitud = -0.307212\n",
            "Iteración 51500: Log-verosimilitud = -0.307201\n",
            "Iteración 52000: Log-verosimilitud = -0.307189\n",
            "Iteración 52500: Log-verosimilitud = -0.307178\n",
            "Iteración 53000: Log-verosimilitud = -0.307167\n",
            "Iteración 53500: Log-verosimilitud = -0.307156\n",
            "Iteración 54000: Log-verosimilitud = -0.307145\n",
            "Iteración 54500: Log-verosimilitud = -0.307135\n",
            "Iteración 55000: Log-verosimilitud = -0.307124\n",
            "Iteración 55500: Log-verosimilitud = -0.307114\n",
            "Iteración 56000: Log-verosimilitud = -0.307104\n",
            "Iteración 56500: Log-verosimilitud = -0.307094\n",
            "Iteración 57000: Log-verosimilitud = -0.307084\n",
            "Iteración 57500: Log-verosimilitud = -0.307074\n",
            "Iteración 58000: Log-verosimilitud = -0.307064\n",
            "Iteración 58500: Log-verosimilitud = -0.307055\n",
            "Iteración 59000: Log-verosimilitud = -0.307046\n",
            "Iteración 59500: Log-verosimilitud = -0.307037\n",
            "Iteración 60000: Log-verosimilitud = -0.307027\n",
            "Iteración 60500: Log-verosimilitud = -0.307019\n",
            "Iteración 61000: Log-verosimilitud = -0.307010\n",
            "Iteración 61500: Log-verosimilitud = -0.307001\n",
            "Iteración 62000: Log-verosimilitud = -0.306992\n",
            "Iteración 62500: Log-verosimilitud = -0.306984\n",
            "Iteración 63000: Log-verosimilitud = -0.306976\n",
            "Iteración 63500: Log-verosimilitud = -0.306967\n",
            "Iteración 64000: Log-verosimilitud = -0.306959\n",
            "Iteración 64500: Log-verosimilitud = -0.306951\n",
            "Iteración 65000: Log-verosimilitud = -0.306943\n",
            "Iteración 65500: Log-verosimilitud = -0.306935\n",
            "Iteración 66000: Log-verosimilitud = -0.306928\n",
            "Iteración 66500: Log-verosimilitud = -0.306920\n",
            "Iteración 67000: Log-verosimilitud = -0.306913\n",
            "Iteración 67500: Log-verosimilitud = -0.306905\n",
            "Iteración 68000: Log-verosimilitud = -0.306898\n",
            "Iteración 68500: Log-verosimilitud = -0.306890\n",
            "Iteración 69000: Log-verosimilitud = -0.306883\n",
            "Iteración 69500: Log-verosimilitud = -0.306876\n",
            "Iteración 70000: Log-verosimilitud = -0.306869\n",
            "Iteración 70500: Log-verosimilitud = -0.306862\n",
            "Iteración 71000: Log-verosimilitud = -0.306855\n",
            "Iteración 71500: Log-verosimilitud = -0.306849\n",
            "Iteración 72000: Log-verosimilitud = -0.306842\n",
            "Iteración 72500: Log-verosimilitud = -0.306835\n",
            "Iteración 73000: Log-verosimilitud = -0.306829\n",
            "Iteración 73500: Log-verosimilitud = -0.306823\n",
            "Iteración 74000: Log-verosimilitud = -0.306816\n",
            "Iteración 74500: Log-verosimilitud = -0.306810\n",
            "Iteración 75000: Log-verosimilitud = -0.306804\n",
            "Iteración 75500: Log-verosimilitud = -0.306798\n",
            "Iteración 76000: Log-verosimilitud = -0.306791\n",
            "Iteración 76500: Log-verosimilitud = -0.306785\n",
            "Iteración 77000: Log-verosimilitud = -0.306779\n",
            "Iteración 77500: Log-verosimilitud = -0.306774\n",
            "Iteración 78000: Log-verosimilitud = -0.306768\n",
            "Iteración 78500: Log-verosimilitud = -0.306762\n",
            "Iteración 79000: Log-verosimilitud = -0.306756\n",
            "Iteración 79500: Log-verosimilitud = -0.306751\n",
            "Iteración 80000: Log-verosimilitud = -0.306745\n",
            "Iteración 80500: Log-verosimilitud = -0.306740\n",
            "Iteración 81000: Log-verosimilitud = -0.306734\n",
            "Iteración 81500: Log-verosimilitud = -0.306729\n",
            "Iteración 82000: Log-verosimilitud = -0.306724\n",
            "Iteración 82500: Log-verosimilitud = -0.306718\n",
            "Iteración 83000: Log-verosimilitud = -0.306713\n",
            "Iteración 83500: Log-verosimilitud = -0.306708\n",
            "Iteración 84000: Log-verosimilitud = -0.306703\n",
            "Iteración 84500: Log-verosimilitud = -0.306698\n",
            "Iteración 85000: Log-verosimilitud = -0.306693\n",
            "Iteración 85500: Log-verosimilitud = -0.306688\n",
            "Iteración 86000: Log-verosimilitud = -0.306683\n",
            "Iteración 86500: Log-verosimilitud = -0.306678\n",
            "Iteración 87000: Log-verosimilitud = -0.306673\n",
            "Iteración 87500: Log-verosimilitud = -0.306669\n",
            "Iteración 88000: Log-verosimilitud = -0.306664\n",
            "Iteración 88500: Log-verosimilitud = -0.306659\n",
            "Iteración 89000: Log-verosimilitud = -0.306655\n",
            "Iteración 89500: Log-verosimilitud = -0.306650\n",
            "Iteración 90000: Log-verosimilitud = -0.306645\n",
            "Iteración 90500: Log-verosimilitud = -0.306641\n",
            "Iteración 91000: Log-verosimilitud = -0.306637\n",
            "Iteración 91500: Log-verosimilitud = -0.306632\n",
            "Iteración 92000: Log-verosimilitud = -0.306628\n",
            "Iteración 92500: Log-verosimilitud = -0.306624\n",
            "Iteración 93000: Log-verosimilitud = -0.306619\n",
            "Iteración 93500: Log-verosimilitud = -0.306615\n",
            "Iteración 94000: Log-verosimilitud = -0.306611\n",
            "Iteración 94500: Log-verosimilitud = -0.306607\n",
            "Iteración 95000: Log-verosimilitud = -0.306603\n",
            "Iteración 95500: Log-verosimilitud = -0.306599\n",
            "Iteración 96000: Log-verosimilitud = -0.306595\n",
            "Iteración 96500: Log-verosimilitud = -0.306591\n",
            "Iteración 97000: Log-verosimilitud = -0.306587\n",
            "Iteración 97500: Log-verosimilitud = -0.306583\n",
            "Iteración 98000: Log-verosimilitud = -0.306579\n",
            "Iteración 98500: Log-verosimilitud = -0.306575\n",
            "Iteración 99000: Log-verosimilitud = -0.306571\n",
            "Iteración 99500: Log-verosimilitud = -0.306567\n",
            "Iteración 100000: Log-verosimilitud = -0.306564\n",
            "Iteración 100500: Log-verosimilitud = -0.306560\n",
            "Iteración 101000: Log-verosimilitud = -0.306556\n",
            "Iteración 101500: Log-verosimilitud = -0.306553\n",
            "Iteración 102000: Log-verosimilitud = -0.306549\n",
            "Iteración 102500: Log-verosimilitud = -0.306545\n",
            "Iteración 103000: Log-verosimilitud = -0.306542\n",
            "Iteración 103500: Log-verosimilitud = -0.306538\n",
            "Iteración 104000: Log-verosimilitud = -0.306535\n",
            "Iteración 104500: Log-verosimilitud = -0.306531\n",
            "Iteración 105000: Log-verosimilitud = -0.306528\n",
            "Iteración 105500: Log-verosimilitud = -0.306525\n",
            "Iteración 106000: Log-verosimilitud = -0.306521\n",
            "Iteración 106500: Log-verosimilitud = -0.306518\n",
            "Iteración 107000: Log-verosimilitud = -0.306515\n",
            "Iteración 107500: Log-verosimilitud = -0.306511\n",
            "Iteración 108000: Log-verosimilitud = -0.306508\n",
            "Iteración 108500: Log-verosimilitud = -0.306505\n",
            "Iteración 109000: Log-verosimilitud = -0.306502\n",
            "Iteración 109500: Log-verosimilitud = -0.306498\n",
            "Iteración 110000: Log-verosimilitud = -0.306495\n",
            "Iteración 110500: Log-verosimilitud = -0.306492\n",
            "Iteración 111000: Log-verosimilitud = -0.306489\n",
            "Iteración 111500: Log-verosimilitud = -0.306486\n",
            "Iteración 112000: Log-verosimilitud = -0.306483\n",
            "Iteración 112500: Log-verosimilitud = -0.306480\n",
            "Iteración 113000: Log-verosimilitud = -0.306477\n",
            "Iteración 113500: Log-verosimilitud = -0.306474\n",
            "Iteración 114000: Log-verosimilitud = -0.306471\n",
            "Iteración 114500: Log-verosimilitud = -0.306468\n",
            "Iteración 115000: Log-verosimilitud = -0.306465\n",
            "Iteración 115500: Log-verosimilitud = -0.306462\n",
            "Iteración 116000: Log-verosimilitud = -0.306459\n",
            "Iteración 116500: Log-verosimilitud = -0.306456\n",
            "Iteración 117000: Log-verosimilitud = -0.306454\n",
            "Iteración 117500: Log-verosimilitud = -0.306451\n",
            "Iteración 118000: Log-verosimilitud = -0.306448\n",
            "Iteración 118500: Log-verosimilitud = -0.306445\n",
            "Iteración 119000: Log-verosimilitud = -0.306443\n",
            "Iteración 119500: Log-verosimilitud = -0.306440\n",
            "Iteración 120000: Log-verosimilitud = -0.306437\n",
            "Iteración 120500: Log-verosimilitud = -0.306435\n",
            "Iteración 121000: Log-verosimilitud = -0.306432\n",
            "Iteración 121500: Log-verosimilitud = -0.306429\n",
            "Iteración 122000: Log-verosimilitud = -0.306427\n",
            "Iteración 122500: Log-verosimilitud = -0.306424\n",
            "Iteración 123000: Log-verosimilitud = -0.306421\n",
            "Iteración 123500: Log-verosimilitud = -0.306419\n",
            "Iteración 124000: Log-verosimilitud = -0.306416\n",
            "Iteración 124500: Log-verosimilitud = -0.306414\n",
            "Iteración 125000: Log-verosimilitud = -0.306411\n",
            "Iteración 125500: Log-verosimilitud = -0.306409\n",
            "Iteración 126000: Log-verosimilitud = -0.306406\n",
            "Iteración 126500: Log-verosimilitud = -0.306404\n",
            "Iteración 127000: Log-verosimilitud = -0.306402\n",
            "Iteración 127500: Log-verosimilitud = -0.306399\n",
            "Iteración 128000: Log-verosimilitud = -0.306397\n",
            "Iteración 128500: Log-verosimilitud = -0.306394\n",
            "Iteración 129000: Log-verosimilitud = -0.306392\n",
            "Iteración 129500: Log-verosimilitud = -0.306390\n",
            "Iteración 130000: Log-verosimilitud = -0.306387\n",
            "Iteración 130500: Log-verosimilitud = -0.306385\n",
            "Iteración 131000: Log-verosimilitud = -0.306383\n",
            "Iteración 131500: Log-verosimilitud = -0.306381\n",
            "Iteración 132000: Log-verosimilitud = -0.306378\n",
            "Iteración 132500: Log-verosimilitud = -0.306376\n",
            "Iteración 133000: Log-verosimilitud = -0.306374\n",
            "Iteración 133500: Log-verosimilitud = -0.306372\n",
            "Iteración 134000: Log-verosimilitud = -0.306369\n",
            "Iteración 134500: Log-verosimilitud = -0.306367\n",
            "Iteración 135000: Log-verosimilitud = -0.306365\n",
            "Iteración 135500: Log-verosimilitud = -0.306363\n",
            "Iteración 136000: Log-verosimilitud = -0.306361\n",
            "Iteración 136500: Log-verosimilitud = -0.306359\n",
            "Iteración 137000: Log-verosimilitud = -0.306357\n",
            "Iteración 137500: Log-verosimilitud = -0.306354\n",
            "Iteración 138000: Log-verosimilitud = -0.306352\n",
            "Iteración 138500: Log-verosimilitud = -0.306350\n",
            "Iteración 139000: Log-verosimilitud = -0.306348\n",
            "Iteración 139500: Log-verosimilitud = -0.306346\n",
            "Iteración 140000: Log-verosimilitud = -0.306344\n",
            "Iteración 140500: Log-verosimilitud = -0.306342\n",
            "Iteración 141000: Log-verosimilitud = -0.306340\n",
            "Iteración 141500: Log-verosimilitud = -0.306338\n",
            "Iteración 142000: Log-verosimilitud = -0.306336\n",
            "Iteración 142500: Log-verosimilitud = -0.306334\n",
            "Iteración 143000: Log-verosimilitud = -0.306332\n",
            "Iteración 143500: Log-verosimilitud = -0.306330\n",
            "Iteración 144000: Log-verosimilitud = -0.306329\n",
            "Iteración 144500: Log-verosimilitud = -0.306327\n",
            "Iteración 145000: Log-verosimilitud = -0.306325\n",
            "Iteración 145500: Log-verosimilitud = -0.306323\n",
            "Iteración 146000: Log-verosimilitud = -0.306321\n",
            "Iteración 146500: Log-verosimilitud = -0.306319\n",
            "Iteración 147000: Log-verosimilitud = -0.306317\n",
            "Iteración 147500: Log-verosimilitud = -0.306315\n",
            "Iteración 148000: Log-verosimilitud = -0.306314\n",
            "Iteración 148500: Log-verosimilitud = -0.306312\n",
            "Iteración 149000: Log-verosimilitud = -0.306310\n",
            "Iteración 149500: Log-verosimilitud = -0.306308\n",
            "Iteración 150000: Log-verosimilitud = -0.306306\n",
            "Iteración 150500: Log-verosimilitud = -0.306305\n",
            "Iteración 151000: Log-verosimilitud = -0.306303\n",
            "Iteración 151500: Log-verosimilitud = -0.306301\n",
            "Iteración 152000: Log-verosimilitud = -0.306299\n",
            "Iteración 152500: Log-verosimilitud = -0.306298\n",
            "Iteración 153000: Log-verosimilitud = -0.306296\n",
            "Iteración 153500: Log-verosimilitud = -0.306294\n",
            "Iteración 154000: Log-verosimilitud = -0.306293\n",
            "Iteración 154500: Log-verosimilitud = -0.306291\n",
            "Iteración 155000: Log-verosimilitud = -0.306289\n",
            "Iteración 155500: Log-verosimilitud = -0.306288\n",
            "Iteración 156000: Log-verosimilitud = -0.306286\n",
            "Iteración 156500: Log-verosimilitud = -0.306284\n",
            "Iteración 157000: Log-verosimilitud = -0.306283\n",
            "Iteración 157500: Log-verosimilitud = -0.306281\n",
            "Iteración 158000: Log-verosimilitud = -0.306279\n",
            "Iteración 158500: Log-verosimilitud = -0.306278\n",
            "Iteración 159000: Log-verosimilitud = -0.306276\n",
            "Iteración 159500: Log-verosimilitud = -0.306275\n",
            "Iteración 160000: Log-verosimilitud = -0.306273\n",
            "Iteración 160500: Log-verosimilitud = -0.306271\n",
            "Iteración 161000: Log-verosimilitud = -0.306270\n",
            "Iteración 161500: Log-verosimilitud = -0.306268\n",
            "Iteración 162000: Log-verosimilitud = -0.306267\n",
            "Iteración 162500: Log-verosimilitud = -0.306265\n",
            "Iteración 163000: Log-verosimilitud = -0.306264\n",
            "Iteración 163500: Log-verosimilitud = -0.306262\n",
            "Iteración 164000: Log-verosimilitud = -0.306261\n",
            "Iteración 164500: Log-verosimilitud = -0.306259\n",
            "Iteración 165000: Log-verosimilitud = -0.306258\n",
            "Iteración 165500: Log-verosimilitud = -0.306256\n",
            "Iteración 166000: Log-verosimilitud = -0.306255\n",
            "Iteración 166500: Log-verosimilitud = -0.306253\n",
            "Iteración 167000: Log-verosimilitud = -0.306252\n",
            "Iteración 167500: Log-verosimilitud = -0.306250\n",
            "Iteración 168000: Log-verosimilitud = -0.306249\n",
            "Iteración 168500: Log-verosimilitud = -0.306248\n",
            "Iteración 169000: Log-verosimilitud = -0.306246\n",
            "Iteración 169500: Log-verosimilitud = -0.306245\n",
            "Iteración 170000: Log-verosimilitud = -0.306243\n",
            "Iteración 170500: Log-verosimilitud = -0.306242\n",
            "Iteración 171000: Log-verosimilitud = -0.306240\n",
            "Iteración 171500: Log-verosimilitud = -0.306239\n",
            "Iteración 172000: Log-verosimilitud = -0.306238\n",
            "Iteración 172500: Log-verosimilitud = -0.306236\n",
            "Iteración 173000: Log-verosimilitud = -0.306235\n",
            "Iteración 173500: Log-verosimilitud = -0.306234\n",
            "Iteración 174000: Log-verosimilitud = -0.306232\n",
            "Iteración 174500: Log-verosimilitud = -0.306231\n",
            "Iteración 175000: Log-verosimilitud = -0.306230\n",
            "Iteración 175500: Log-verosimilitud = -0.306228\n",
            "Iteración 176000: Log-verosimilitud = -0.306227\n",
            "Iteración 176500: Log-verosimilitud = -0.306226\n",
            "Iteración 177000: Log-verosimilitud = -0.306224\n",
            "Iteración 177500: Log-verosimilitud = -0.306223\n",
            "Iteración 178000: Log-verosimilitud = -0.306222\n",
            "Iteración 178500: Log-verosimilitud = -0.306221\n",
            "Iteración 179000: Log-verosimilitud = -0.306219\n",
            "Iteración 179500: Log-verosimilitud = -0.306218\n",
            "Iteración 180000: Log-verosimilitud = -0.306217\n",
            "Iteración 180500: Log-verosimilitud = -0.306215\n",
            "Iteración 181000: Log-verosimilitud = -0.306214\n",
            "Iteración 181500: Log-verosimilitud = -0.306213\n",
            "Iteración 182000: Log-verosimilitud = -0.306212\n",
            "Iteración 182500: Log-verosimilitud = -0.306210\n",
            "Iteración 183000: Log-verosimilitud = -0.306209\n",
            "Iteración 183500: Log-verosimilitud = -0.306208\n",
            "Iteración 184000: Log-verosimilitud = -0.306207\n",
            "Iteración 184500: Log-verosimilitud = -0.306206\n",
            "Iteración 185000: Log-verosimilitud = -0.306204\n",
            "Iteración 185500: Log-verosimilitud = -0.306203\n",
            "Iteración 186000: Log-verosimilitud = -0.306202\n",
            "Iteración 186500: Log-verosimilitud = -0.306201\n",
            "Iteración 187000: Log-verosimilitud = -0.306200\n",
            "Iteración 187500: Log-verosimilitud = -0.306199\n",
            "Iteración 188000: Log-verosimilitud = -0.306197\n",
            "Iteración 188500: Log-verosimilitud = -0.306196\n",
            "Iteración 189000: Log-verosimilitud = -0.306195\n",
            "Iteración 189500: Log-verosimilitud = -0.306194\n",
            "Iteración 190000: Log-verosimilitud = -0.306193\n",
            "Iteración 190500: Log-verosimilitud = -0.306192\n",
            "Iteración 191000: Log-verosimilitud = -0.306190\n",
            "Iteración 191500: Log-verosimilitud = -0.306189\n",
            "Iteración 192000: Log-verosimilitud = -0.306188\n",
            "Iteración 192500: Log-verosimilitud = -0.306187\n",
            "Iteración 193000: Log-verosimilitud = -0.306186\n",
            "Iteración 193500: Log-verosimilitud = -0.306185\n",
            "Iteración 194000: Log-verosimilitud = -0.306184\n",
            "Iteración 194500: Log-verosimilitud = -0.306183\n",
            "Iteración 195000: Log-verosimilitud = -0.306182\n",
            "Iteración 195500: Log-verosimilitud = -0.306181\n",
            "Iteración 196000: Log-verosimilitud = -0.306180\n",
            "Iteración 196500: Log-verosimilitud = -0.306178\n",
            "Iteración 197000: Log-verosimilitud = -0.306177\n",
            "Iteración 197500: Log-verosimilitud = -0.306176\n",
            "Iteración 198000: Log-verosimilitud = -0.306175\n",
            "Iteración 198500: Log-verosimilitud = -0.306174\n",
            "Iteración 199000: Log-verosimilitud = -0.306173\n",
            "Iteración 199500: Log-verosimilitud = -0.306172\n",
            "Iteración 200000: Log-verosimilitud = -0.306171\n",
            "Iteración 200500: Log-verosimilitud = -0.306170\n",
            "Iteración 201000: Log-verosimilitud = -0.306169\n",
            "Iteración 201500: Log-verosimilitud = -0.306168\n",
            "Iteración 202000: Log-verosimilitud = -0.306167\n",
            "Iteración 202500: Log-verosimilitud = -0.306166\n",
            "Iteración 203000: Log-verosimilitud = -0.306165\n",
            "Iteración 203500: Log-verosimilitud = -0.306164\n",
            "Iteración 204000: Log-verosimilitud = -0.306163\n",
            "Iteración 204500: Log-verosimilitud = -0.306162\n",
            "Iteración 205000: Log-verosimilitud = -0.306161\n",
            "Iteración 205500: Log-verosimilitud = -0.306160\n",
            "Iteración 206000: Log-verosimilitud = -0.306159\n",
            "Iteración 206500: Log-verosimilitud = -0.306158\n",
            "Iteración 207000: Log-verosimilitud = -0.306157\n",
            "Iteración 207500: Log-verosimilitud = -0.306156\n",
            "Iteración 208000: Log-verosimilitud = -0.306155\n",
            "Iteración 208500: Log-verosimilitud = -0.306154\n",
            "Iteración 209000: Log-verosimilitud = -0.306153\n",
            "Iteración 209500: Log-verosimilitud = -0.306152\n",
            "Iteración 210000: Log-verosimilitud = -0.306151\n",
            "Iteración 210500: Log-verosimilitud = -0.306150\n",
            "Iteración 211000: Log-verosimilitud = -0.306150\n",
            "Iteración 211500: Log-verosimilitud = -0.306149\n",
            "Iteración 212000: Log-verosimilitud = -0.306148\n",
            "Iteración 212500: Log-verosimilitud = -0.306147\n",
            "Iteración 213000: Log-verosimilitud = -0.306146\n",
            "Iteración 213500: Log-verosimilitud = -0.306145\n",
            "Iteración 214000: Log-verosimilitud = -0.306144\n",
            "Iteración 214500: Log-verosimilitud = -0.306143\n",
            "Iteración 215000: Log-verosimilitud = -0.306142\n",
            "Iteración 215500: Log-verosimilitud = -0.306141\n",
            "Iteración 216000: Log-verosimilitud = -0.306140\n",
            "Iteración 216500: Log-verosimilitud = -0.306140\n",
            "Iteración 217000: Log-verosimilitud = -0.306139\n",
            "Iteración 217500: Log-verosimilitud = -0.306138\n",
            "Iteración 218000: Log-verosimilitud = -0.306137\n",
            "Iteración 218500: Log-verosimilitud = -0.306136\n",
            "Iteración 219000: Log-verosimilitud = -0.306135\n",
            "Iteración 219500: Log-verosimilitud = -0.306134\n",
            "Iteración 220000: Log-verosimilitud = -0.306133\n",
            "Iteración 220500: Log-verosimilitud = -0.306133\n",
            "Iteración 221000: Log-verosimilitud = -0.306132\n",
            "Iteración 221500: Log-verosimilitud = -0.306131\n",
            "Iteración 222000: Log-verosimilitud = -0.306130\n",
            "Iteración 222500: Log-verosimilitud = -0.306129\n",
            "Iteración 223000: Log-verosimilitud = -0.306128\n",
            "Iteración 223500: Log-verosimilitud = -0.306127\n",
            "Iteración 224000: Log-verosimilitud = -0.306127\n",
            "Iteración 224500: Log-verosimilitud = -0.306126\n",
            "Iteración 225000: Log-verosimilitud = -0.306125\n",
            "Iteración 225500: Log-verosimilitud = -0.306124\n",
            "Iteración 226000: Log-verosimilitud = -0.306123\n",
            "Iteración 226500: Log-verosimilitud = -0.306123\n",
            "Iteración 227000: Log-verosimilitud = -0.306122\n",
            "Iteración 227500: Log-verosimilitud = -0.306121\n",
            "Iteración 228000: Log-verosimilitud = -0.306120\n",
            "Iteración 228500: Log-verosimilitud = -0.306119\n",
            "Iteración 229000: Log-verosimilitud = -0.306119\n",
            "Iteración 229500: Log-verosimilitud = -0.306118\n",
            "Iteración 230000: Log-verosimilitud = -0.306117\n",
            "Iteración 230500: Log-verosimilitud = -0.306116\n",
            "Iteración 231000: Log-verosimilitud = -0.306115\n",
            "Iteración 231500: Log-verosimilitud = -0.306115\n",
            "Iteración 232000: Log-verosimilitud = -0.306114\n",
            "Iteración 232500: Log-verosimilitud = -0.306113\n",
            "Iteración 233000: Log-verosimilitud = -0.306112\n",
            "Iteración 233500: Log-verosimilitud = -0.306111\n",
            "Iteración 234000: Log-verosimilitud = -0.306111\n",
            "Iteración 234500: Log-verosimilitud = -0.306110\n",
            "Iteración 235000: Log-verosimilitud = -0.306109\n",
            "Iteración 235500: Log-verosimilitud = -0.306108\n",
            "Iteración 236000: Log-verosimilitud = -0.306108\n",
            "Iteración 236500: Log-verosimilitud = -0.306107\n",
            "Iteración 237000: Log-verosimilitud = -0.306106\n",
            "Iteración 237500: Log-verosimilitud = -0.306105\n",
            "Iteración 238000: Log-verosimilitud = -0.306105\n",
            "Iteración 238500: Log-verosimilitud = -0.306104\n",
            "Iteración 239000: Log-verosimilitud = -0.306103\n",
            "Iteración 239500: Log-verosimilitud = -0.306103\n",
            "Iteración 240000: Log-verosimilitud = -0.306102\n",
            "Iteración 240500: Log-verosimilitud = -0.306101\n",
            "Iteración 241000: Log-verosimilitud = -0.306100\n",
            "Iteración 241500: Log-verosimilitud = -0.306100\n",
            "Iteración 242000: Log-verosimilitud = -0.306099\n",
            "Iteración 242500: Log-verosimilitud = -0.306098\n",
            "Iteración 243000: Log-verosimilitud = -0.306097\n",
            "Iteración 243500: Log-verosimilitud = -0.306097\n",
            "Iteración 244000: Log-verosimilitud = -0.306096\n",
            "Iteración 244500: Log-verosimilitud = -0.306095\n",
            "Iteración 245000: Log-verosimilitud = -0.306095\n",
            "Iteración 245500: Log-verosimilitud = -0.306094\n",
            "Iteración 246000: Log-verosimilitud = -0.306093\n",
            "Iteración 246500: Log-verosimilitud = -0.306093\n",
            "Iteración 247000: Log-verosimilitud = -0.306092\n",
            "Iteración 247500: Log-verosimilitud = -0.306091\n",
            "Iteración 248000: Log-verosimilitud = -0.306091\n",
            "Iteración 248500: Log-verosimilitud = -0.306090\n",
            "Iteración 249000: Log-verosimilitud = -0.306089\n",
            "Iteración 249500: Log-verosimilitud = -0.306088\n",
            "Iteración 250000: Log-verosimilitud = -0.306088\n",
            "Iteración 250500: Log-verosimilitud = -0.306087\n",
            "Iteración 251000: Log-verosimilitud = -0.306086\n",
            "Iteración 251500: Log-verosimilitud = -0.306086\n",
            "Iteración 252000: Log-verosimilitud = -0.306085\n",
            "Iteración 252500: Log-verosimilitud = -0.306084\n",
            "Iteración 253000: Log-verosimilitud = -0.306084\n",
            "Iteración 253500: Log-verosimilitud = -0.306083\n",
            "Iteración 254000: Log-verosimilitud = -0.306082\n",
            "Iteración 254500: Log-verosimilitud = -0.306082\n",
            "Iteración 255000: Log-verosimilitud = -0.306081\n",
            "Iteración 255500: Log-verosimilitud = -0.306081\n",
            "Iteración 256000: Log-verosimilitud = -0.306080\n",
            "Iteración 256500: Log-verosimilitud = -0.306079\n",
            "Iteración 257000: Log-verosimilitud = -0.306079\n",
            "Iteración 257500: Log-verosimilitud = -0.306078\n",
            "Iteración 258000: Log-verosimilitud = -0.306077\n",
            "Iteración 258500: Log-verosimilitud = -0.306077\n",
            "Iteración 259000: Log-verosimilitud = -0.306076\n",
            "Iteración 259500: Log-verosimilitud = -0.306075\n",
            "Iteración 260000: Log-verosimilitud = -0.306075\n",
            "Iteración 260500: Log-verosimilitud = -0.306074\n",
            "Iteración 261000: Log-verosimilitud = -0.306074\n",
            "Iteración 261500: Log-verosimilitud = -0.306073\n",
            "Iteración 262000: Log-verosimilitud = -0.306072\n",
            "Iteración 262500: Log-verosimilitud = -0.306072\n",
            "Iteración 263000: Log-verosimilitud = -0.306071\n",
            "Iteración 263500: Log-verosimilitud = -0.306071\n",
            "Iteración 264000: Log-verosimilitud = -0.306070\n",
            "Iteración 264500: Log-verosimilitud = -0.306069\n",
            "Iteración 265000: Log-verosimilitud = -0.306069\n",
            "Iteración 265500: Log-verosimilitud = -0.306068\n",
            "Iteración 266000: Log-verosimilitud = -0.306068\n",
            "Iteración 266500: Log-verosimilitud = -0.306067\n",
            "Iteración 267000: Log-verosimilitud = -0.306066\n",
            "Iteración 267500: Log-verosimilitud = -0.306066\n",
            "Iteración 268000: Log-verosimilitud = -0.306065\n",
            "Iteración 268500: Log-verosimilitud = -0.306065\n",
            "Iteración 269000: Log-verosimilitud = -0.306064\n",
            "Iteración 269500: Log-verosimilitud = -0.306063\n",
            "Iteración 270000: Log-verosimilitud = -0.306063\n",
            "Iteración 270500: Log-verosimilitud = -0.306062\n",
            "Iteración 271000: Log-verosimilitud = -0.306062\n",
            "Iteración 271500: Log-verosimilitud = -0.306061\n",
            "Iteración 272000: Log-verosimilitud = -0.306061\n",
            "Iteración 272500: Log-verosimilitud = -0.306060\n",
            "Iteración 273000: Log-verosimilitud = -0.306059\n",
            "Iteración 273500: Log-verosimilitud = -0.306059\n",
            "Iteración 274000: Log-verosimilitud = -0.306058\n",
            "Iteración 274500: Log-verosimilitud = -0.306058\n",
            "Iteración 275000: Log-verosimilitud = -0.306057\n",
            "Iteración 275500: Log-verosimilitud = -0.306057\n",
            "Iteración 276000: Log-verosimilitud = -0.306056\n",
            "Iteración 276500: Log-verosimilitud = -0.306055\n",
            "Iteración 277000: Log-verosimilitud = -0.306055\n",
            "Iteración 277500: Log-verosimilitud = -0.306054\n",
            "Iteración 278000: Log-verosimilitud = -0.306054\n",
            "Iteración 278500: Log-verosimilitud = -0.306053\n",
            "Iteración 279000: Log-verosimilitud = -0.306053\n",
            "Iteración 279500: Log-verosimilitud = -0.306052\n",
            "Iteración 280000: Log-verosimilitud = -0.306052\n",
            "Iteración 280500: Log-verosimilitud = -0.306051\n",
            "Iteración 281000: Log-verosimilitud = -0.306051\n",
            "Iteración 281500: Log-verosimilitud = -0.306050\n",
            "Iteración 282000: Log-verosimilitud = -0.306049\n",
            "Iteración 282500: Log-verosimilitud = -0.306049\n",
            "Iteración 283000: Log-verosimilitud = -0.306048\n",
            "Iteración 283500: Log-verosimilitud = -0.306048\n",
            "Iteración 284000: Log-verosimilitud = -0.306047\n",
            "Iteración 284500: Log-verosimilitud = -0.306047\n",
            "Iteración 285000: Log-verosimilitud = -0.306046\n",
            "Iteración 285500: Log-verosimilitud = -0.306046\n",
            "Iteración 286000: Log-verosimilitud = -0.306045\n",
            "Iteración 286500: Log-verosimilitud = -0.306045\n",
            "Iteración 287000: Log-verosimilitud = -0.306044\n",
            "Iteración 287500: Log-verosimilitud = -0.306044\n",
            "Iteración 288000: Log-verosimilitud = -0.306043\n",
            "Iteración 288500: Log-verosimilitud = -0.306043\n",
            "Iteración 289000: Log-verosimilitud = -0.306042\n",
            "Iteración 289500: Log-verosimilitud = -0.306042\n",
            "Iteración 290000: Log-verosimilitud = -0.306041\n",
            "Iteración 290500: Log-verosimilitud = -0.306041\n",
            "Iteración 291000: Log-verosimilitud = -0.306040\n",
            "\n",
            "Coeficientes finales:\n",
            "[-1.30906486 -0.38671538  0.71610476  0.19286717 -0.91987389  0.20457372\n",
            " -1.47824542  0.16918056 -1.4929796  -0.90229768 -0.22077513  1.30698755\n",
            " -0.6506375  -0.65842736 -2.14546734  2.50409674 -1.66769427 -1.01051119\n",
            " -0.29855367 -0.53359665  0.02775109 -0.8032193   2.08956598  3.56169813\n",
            "  5.48779964  4.1176441   1.2349587   1.36986303  2.6424181 ]\n",
            "Número total de iteraciones: 291433\n",
            "===== Entrenando con learning rate = 0.0100 =====\n",
            "Iteración 0: Log-verosimilitud = -0.693145\n",
            "Iteración 500: Log-verosimilitud = -0.405798\n",
            "Iteración 1000: Log-verosimilitud = -0.369893\n",
            "Iteración 1500: Log-verosimilitud = -0.354149\n",
            "Iteración 2000: Log-verosimilitud = -0.344954\n",
            "Iteración 2500: Log-verosimilitud = -0.338824\n",
            "Iteración 3000: Log-verosimilitud = -0.334405\n",
            "Iteración 3500: Log-verosimilitud = -0.331054\n",
            "Iteración 4000: Log-verosimilitud = -0.328420\n",
            "Iteración 4500: Log-verosimilitud = -0.326298\n",
            "Iteración 5000: Log-verosimilitud = -0.324553\n",
            "Iteración 5500: Log-verosimilitud = -0.323096\n",
            "Iteración 6000: Log-verosimilitud = -0.321863\n",
            "Iteración 6500: Log-verosimilitud = -0.320809\n",
            "Iteración 7000: Log-verosimilitud = -0.319900\n",
            "Iteración 7500: Log-verosimilitud = -0.319109\n",
            "Iteración 8000: Log-verosimilitud = -0.318416\n",
            "Iteración 8500: Log-verosimilitud = -0.317806\n",
            "Iteración 9000: Log-verosimilitud = -0.317265\n",
            "Iteración 9500: Log-verosimilitud = -0.316783\n",
            "Iteración 10000: Log-verosimilitud = -0.316351\n",
            "Iteración 10500: Log-verosimilitud = -0.315964\n",
            "Iteración 11000: Log-verosimilitud = -0.315614\n",
            "Iteración 11500: Log-verosimilitud = -0.315298\n",
            "Iteración 12000: Log-verosimilitud = -0.315011\n",
            "Iteración 12500: Log-verosimilitud = -0.314749\n",
            "Iteración 13000: Log-verosimilitud = -0.314510\n",
            "Iteración 13500: Log-verosimilitud = -0.314291\n",
            "Iteración 14000: Log-verosimilitud = -0.314090\n",
            "Iteración 14500: Log-verosimilitud = -0.313905\n",
            "Iteración 15000: Log-verosimilitud = -0.313735\n",
            "Iteración 15500: Log-verosimilitud = -0.313577\n",
            "Iteración 16000: Log-verosimilitud = -0.313431\n",
            "Iteración 16500: Log-verosimilitud = -0.313296\n",
            "Iteración 17000: Log-verosimilitud = -0.313170\n",
            "Iteración 17500: Log-verosimilitud = -0.313052\n",
            "Iteración 18000: Log-verosimilitud = -0.312942\n",
            "Iteración 18500: Log-verosimilitud = -0.312840\n",
            "Iteración 19000: Log-verosimilitud = -0.312744\n",
            "Iteración 19500: Log-verosimilitud = -0.312654\n",
            "Iteración 20000: Log-verosimilitud = -0.312569\n",
            "Iteración 20500: Log-verosimilitud = -0.312490\n",
            "Iteración 21000: Log-verosimilitud = -0.312414\n",
            "Iteración 21500: Log-verosimilitud = -0.312344\n",
            "Iteración 22000: Log-verosimilitud = -0.312276\n",
            "Iteración 22500: Log-verosimilitud = -0.312213\n",
            "Iteración 23000: Log-verosimilitud = -0.312153\n",
            "Iteración 23500: Log-verosimilitud = -0.312096\n",
            "Iteración 24000: Log-verosimilitud = -0.312041\n",
            "Iteración 24500: Log-verosimilitud = -0.311989\n",
            "Iteración 25000: Log-verosimilitud = -0.311940\n",
            "Iteración 25500: Log-verosimilitud = -0.311893\n",
            "Iteración 26000: Log-verosimilitud = -0.311848\n",
            "Iteración 26500: Log-verosimilitud = -0.311805\n",
            "Iteración 27000: Log-verosimilitud = -0.311763\n",
            "Iteración 27500: Log-verosimilitud = -0.311724\n",
            "Iteración 28000: Log-verosimilitud = -0.311686\n",
            "Iteración 28500: Log-verosimilitud = -0.311649\n",
            "Iteración 29000: Log-verosimilitud = -0.311614\n",
            "Iteración 29500: Log-verosimilitud = -0.311580\n",
            "Iteración 30000: Log-verosimilitud = -0.311547\n",
            "Iteración 30500: Log-verosimilitud = -0.311515\n",
            "Iteración 31000: Log-verosimilitud = -0.311484\n",
            "Iteración 31500: Log-verosimilitud = -0.311455\n",
            "Iteración 32000: Log-verosimilitud = -0.311426\n",
            "Iteración 32500: Log-verosimilitud = -0.311398\n",
            "Iteración 33000: Log-verosimilitud = -0.311371\n",
            "Iteración 33500: Log-verosimilitud = -0.311345\n",
            "Iteración 34000: Log-verosimilitud = -0.311319\n",
            "Iteración 34500: Log-verosimilitud = -0.311295\n",
            "Iteración 35000: Log-verosimilitud = -0.311270\n",
            "Iteración 35500: Log-verosimilitud = -0.311247\n",
            "Iteración 36000: Log-verosimilitud = -0.311224\n",
            "Iteración 36500: Log-verosimilitud = -0.311201\n",
            "Iteración 37000: Log-verosimilitud = -0.311180\n",
            "Iteración 37500: Log-verosimilitud = -0.311158\n",
            "Iteración 38000: Log-verosimilitud = -0.311137\n",
            "Iteración 38500: Log-verosimilitud = -0.311117\n",
            "Iteración 39000: Log-verosimilitud = -0.311097\n",
            "Iteración 39500: Log-verosimilitud = -0.311077\n",
            "Iteración 40000: Log-verosimilitud = -0.311058\n",
            "Iteración 40500: Log-verosimilitud = -0.311039\n",
            "Iteración 41000: Log-verosimilitud = -0.311020\n",
            "Iteración 41500: Log-verosimilitud = -0.311002\n",
            "Iteración 42000: Log-verosimilitud = -0.310984\n",
            "Iteración 42500: Log-verosimilitud = -0.310967\n",
            "Iteración 43000: Log-verosimilitud = -0.310950\n",
            "Iteración 43500: Log-verosimilitud = -0.310933\n",
            "Iteración 44000: Log-verosimilitud = -0.310916\n",
            "Iteración 44500: Log-verosimilitud = -0.310899\n",
            "Iteración 45000: Log-verosimilitud = -0.310883\n",
            "Iteración 45500: Log-verosimilitud = -0.310867\n",
            "Iteración 46000: Log-verosimilitud = -0.310851\n",
            "Iteración 46500: Log-verosimilitud = -0.310836\n",
            "Iteración 47000: Log-verosimilitud = -0.310821\n",
            "Iteración 47500: Log-verosimilitud = -0.310805\n",
            "Iteración 48000: Log-verosimilitud = -0.310791\n",
            "Iteración 48500: Log-verosimilitud = -0.310776\n",
            "Iteración 49000: Log-verosimilitud = -0.310761\n",
            "Iteración 49500: Log-verosimilitud = -0.310747\n",
            "Iteración 50000: Log-verosimilitud = -0.310733\n",
            "Iteración 50500: Log-verosimilitud = -0.310719\n",
            "Iteración 51000: Log-verosimilitud = -0.310705\n",
            "Iteración 51500: Log-verosimilitud = -0.310691\n",
            "Iteración 52000: Log-verosimilitud = -0.310677\n",
            "Iteración 52500: Log-verosimilitud = -0.310664\n",
            "Iteración 53000: Log-verosimilitud = -0.310651\n",
            "Iteración 53500: Log-verosimilitud = -0.310637\n",
            "Iteración 54000: Log-verosimilitud = -0.310624\n",
            "Iteración 54500: Log-verosimilitud = -0.310611\n",
            "Iteración 55000: Log-verosimilitud = -0.310599\n",
            "Iteración 55500: Log-verosimilitud = -0.310586\n",
            "Iteración 56000: Log-verosimilitud = -0.310573\n",
            "Iteración 56500: Log-verosimilitud = -0.310561\n",
            "Iteración 57000: Log-verosimilitud = -0.310549\n",
            "Iteración 57500: Log-verosimilitud = -0.310536\n",
            "Iteración 58000: Log-verosimilitud = -0.310524\n",
            "Iteración 58500: Log-verosimilitud = -0.310512\n",
            "Iteración 59000: Log-verosimilitud = -0.310500\n",
            "Iteración 59500: Log-verosimilitud = -0.310488\n",
            "Iteración 60000: Log-verosimilitud = -0.310477\n",
            "Iteración 60500: Log-verosimilitud = -0.310465\n",
            "Iteración 61000: Log-verosimilitud = -0.310453\n",
            "Iteración 61500: Log-verosimilitud = -0.310442\n",
            "Iteración 62000: Log-verosimilitud = -0.310430\n",
            "Iteración 62500: Log-verosimilitud = -0.310419\n",
            "Iteración 63000: Log-verosimilitud = -0.310408\n",
            "Iteración 63500: Log-verosimilitud = -0.310397\n",
            "Iteración 64000: Log-verosimilitud = -0.310385\n",
            "Iteración 64500: Log-verosimilitud = -0.310374\n",
            "Iteración 65000: Log-verosimilitud = -0.310363\n",
            "Iteración 65500: Log-verosimilitud = -0.310353\n",
            "Iteración 66000: Log-verosimilitud = -0.310342\n",
            "Iteración 66500: Log-verosimilitud = -0.310331\n",
            "Iteración 67000: Log-verosimilitud = -0.310320\n",
            "Iteración 67500: Log-verosimilitud = -0.310310\n",
            "Iteración 68000: Log-verosimilitud = -0.310299\n",
            "Iteración 68500: Log-verosimilitud = -0.310289\n",
            "Iteración 69000: Log-verosimilitud = -0.310278\n",
            "Iteración 69500: Log-verosimilitud = -0.310268\n",
            "Iteración 70000: Log-verosimilitud = -0.310258\n",
            "Iteración 70500: Log-verosimilitud = -0.310247\n",
            "Iteración 71000: Log-verosimilitud = -0.310237\n",
            "Iteración 71500: Log-verosimilitud = -0.310227\n",
            "Iteración 72000: Log-verosimilitud = -0.310217\n",
            "Iteración 72500: Log-verosimilitud = -0.310207\n",
            "Iteración 73000: Log-verosimilitud = -0.310197\n",
            "Iteración 73500: Log-verosimilitud = -0.310187\n",
            "Iteración 74000: Log-verosimilitud = -0.310177\n",
            "Iteración 74500: Log-verosimilitud = -0.310167\n",
            "Iteración 75000: Log-verosimilitud = -0.310158\n",
            "Iteración 75500: Log-verosimilitud = -0.310148\n",
            "Iteración 76000: Log-verosimilitud = -0.310138\n",
            "Iteración 76500: Log-verosimilitud = -0.310129\n",
            "Iteración 77000: Log-verosimilitud = -0.310119\n",
            "Iteración 77500: Log-verosimilitud = -0.310110\n",
            "Iteración 78000: Log-verosimilitud = -0.310100\n",
            "Iteración 78500: Log-verosimilitud = -0.310091\n",
            "Iteración 79000: Log-verosimilitud = -0.310081\n",
            "Iteración 79500: Log-verosimilitud = -0.310072\n",
            "Iteración 80000: Log-verosimilitud = -0.310063\n",
            "Iteración 80500: Log-verosimilitud = -0.310054\n",
            "Iteración 81000: Log-verosimilitud = -0.310044\n",
            "Iteración 81500: Log-verosimilitud = -0.310035\n",
            "Iteración 82000: Log-verosimilitud = -0.310026\n",
            "Iteración 82500: Log-verosimilitud = -0.310017\n",
            "Iteración 83000: Log-verosimilitud = -0.310008\n",
            "Iteración 83500: Log-verosimilitud = -0.309999\n",
            "Iteración 84000: Log-verosimilitud = -0.309990\n",
            "Iteración 84500: Log-verosimilitud = -0.309981\n",
            "Iteración 85000: Log-verosimilitud = -0.309972\n",
            "Iteración 85500: Log-verosimilitud = -0.309963\n",
            "Iteración 86000: Log-verosimilitud = -0.309955\n",
            "Iteración 86500: Log-verosimilitud = -0.309946\n",
            "Iteración 87000: Log-verosimilitud = -0.309937\n",
            "Iteración 87500: Log-verosimilitud = -0.309928\n",
            "Iteración 88000: Log-verosimilitud = -0.309920\n",
            "Iteración 88500: Log-verosimilitud = -0.309911\n",
            "Iteración 89000: Log-verosimilitud = -0.309903\n",
            "Iteración 89500: Log-verosimilitud = -0.309894\n",
            "Iteración 90000: Log-verosimilitud = -0.309886\n",
            "Iteración 90500: Log-verosimilitud = -0.309877\n",
            "Iteración 91000: Log-verosimilitud = -0.309869\n",
            "Iteración 91500: Log-verosimilitud = -0.309860\n",
            "Iteración 92000: Log-verosimilitud = -0.309852\n",
            "Iteración 92500: Log-verosimilitud = -0.309844\n",
            "Iteración 93000: Log-verosimilitud = -0.309835\n",
            "Iteración 93500: Log-verosimilitud = -0.309827\n",
            "Iteración 94000: Log-verosimilitud = -0.309819\n",
            "Iteración 94500: Log-verosimilitud = -0.309811\n",
            "Iteración 95000: Log-verosimilitud = -0.309803\n",
            "Iteración 95500: Log-verosimilitud = -0.309795\n",
            "Iteración 96000: Log-verosimilitud = -0.309786\n",
            "Iteración 96500: Log-verosimilitud = -0.309778\n",
            "Iteración 97000: Log-verosimilitud = -0.309770\n",
            "Iteración 97500: Log-verosimilitud = -0.309762\n",
            "Iteración 98000: Log-verosimilitud = -0.309754\n",
            "Iteración 98500: Log-verosimilitud = -0.309747\n",
            "Iteración 99000: Log-verosimilitud = -0.309739\n",
            "Iteración 99500: Log-verosimilitud = -0.309731\n",
            "Iteración 100000: Log-verosimilitud = -0.309723\n",
            "Iteración 100500: Log-verosimilitud = -0.309715\n",
            "Iteración 101000: Log-verosimilitud = -0.309707\n",
            "Iteración 101500: Log-verosimilitud = -0.309700\n",
            "Iteración 102000: Log-verosimilitud = -0.309692\n",
            "Iteración 102500: Log-verosimilitud = -0.309684\n",
            "Iteración 103000: Log-verosimilitud = -0.309677\n",
            "Iteración 103500: Log-verosimilitud = -0.309669\n",
            "Iteración 104000: Log-verosimilitud = -0.309661\n",
            "Iteración 104500: Log-verosimilitud = -0.309654\n",
            "Iteración 105000: Log-verosimilitud = -0.309646\n",
            "Iteración 105500: Log-verosimilitud = -0.309639\n",
            "Iteración 106000: Log-verosimilitud = -0.309631\n",
            "Iteración 106500: Log-verosimilitud = -0.309624\n",
            "Iteración 107000: Log-verosimilitud = -0.309616\n",
            "Iteración 107500: Log-verosimilitud = -0.309609\n",
            "Iteración 108000: Log-verosimilitud = -0.309602\n",
            "Iteración 108500: Log-verosimilitud = -0.309594\n",
            "Iteración 109000: Log-verosimilitud = -0.309587\n",
            "Iteración 109500: Log-verosimilitud = -0.309580\n",
            "Iteración 110000: Log-verosimilitud = -0.309572\n",
            "Iteración 110500: Log-verosimilitud = -0.309565\n",
            "Iteración 111000: Log-verosimilitud = -0.309558\n",
            "Iteración 111500: Log-verosimilitud = -0.309551\n",
            "Iteración 112000: Log-verosimilitud = -0.309544\n",
            "Iteración 112500: Log-verosimilitud = -0.309536\n",
            "Iteración 113000: Log-verosimilitud = -0.309529\n",
            "Iteración 113500: Log-verosimilitud = -0.309522\n",
            "Iteración 114000: Log-verosimilitud = -0.309515\n",
            "Iteración 114500: Log-verosimilitud = -0.309508\n",
            "Iteración 115000: Log-verosimilitud = -0.309501\n",
            "Iteración 115500: Log-verosimilitud = -0.309494\n",
            "Iteración 116000: Log-verosimilitud = -0.309487\n",
            "Iteración 116500: Log-verosimilitud = -0.309480\n",
            "Iteración 117000: Log-verosimilitud = -0.309473\n",
            "Iteración 117500: Log-verosimilitud = -0.309466\n",
            "Iteración 118000: Log-verosimilitud = -0.309460\n",
            "Iteración 118500: Log-verosimilitud = -0.309453\n",
            "Iteración 119000: Log-verosimilitud = -0.309446\n",
            "Iteración 119500: Log-verosimilitud = -0.309439\n",
            "Iteración 120000: Log-verosimilitud = -0.309432\n",
            "Iteración 120500: Log-verosimilitud = -0.309426\n",
            "Iteración 121000: Log-verosimilitud = -0.309419\n",
            "Iteración 121500: Log-verosimilitud = -0.309412\n",
            "Iteración 122000: Log-verosimilitud = -0.309405\n",
            "Iteración 122500: Log-verosimilitud = -0.309399\n",
            "Iteración 123000: Log-verosimilitud = -0.309392\n",
            "Iteración 123500: Log-verosimilitud = -0.309386\n",
            "Iteración 124000: Log-verosimilitud = -0.309379\n",
            "Iteración 124500: Log-verosimilitud = -0.309372\n",
            "Iteración 125000: Log-verosimilitud = -0.309366\n",
            "Iteración 125500: Log-verosimilitud = -0.309359\n",
            "Iteración 126000: Log-verosimilitud = -0.309353\n",
            "Iteración 126500: Log-verosimilitud = -0.309346\n",
            "Iteración 127000: Log-verosimilitud = -0.309340\n",
            "Iteración 127500: Log-verosimilitud = -0.309334\n",
            "Iteración 128000: Log-verosimilitud = -0.309327\n",
            "Iteración 128500: Log-verosimilitud = -0.309321\n",
            "Iteración 129000: Log-verosimilitud = -0.309314\n",
            "Iteración 129500: Log-verosimilitud = -0.309308\n",
            "Iteración 130000: Log-verosimilitud = -0.309302\n",
            "Iteración 130500: Log-verosimilitud = -0.309295\n",
            "Iteración 131000: Log-verosimilitud = -0.309289\n",
            "Iteración 131500: Log-verosimilitud = -0.309283\n",
            "Iteración 132000: Log-verosimilitud = -0.309277\n",
            "Iteración 132500: Log-verosimilitud = -0.309270\n",
            "Iteración 133000: Log-verosimilitud = -0.309264\n",
            "Iteración 133500: Log-verosimilitud = -0.309258\n",
            "Iteración 134000: Log-verosimilitud = -0.309252\n",
            "Iteración 134500: Log-verosimilitud = -0.309246\n",
            "Iteración 135000: Log-verosimilitud = -0.309240\n",
            "Iteración 135500: Log-verosimilitud = -0.309234\n",
            "Iteración 136000: Log-verosimilitud = -0.309228\n",
            "Iteración 136500: Log-verosimilitud = -0.309221\n",
            "Iteración 137000: Log-verosimilitud = -0.309215\n",
            "Iteración 137500: Log-verosimilitud = -0.309209\n",
            "Iteración 138000: Log-verosimilitud = -0.309203\n",
            "Iteración 138500: Log-verosimilitud = -0.309197\n",
            "Iteración 139000: Log-verosimilitud = -0.309191\n",
            "Iteración 139500: Log-verosimilitud = -0.309186\n",
            "Iteración 140000: Log-verosimilitud = -0.309180\n",
            "Iteración 140500: Log-verosimilitud = -0.309174\n",
            "Iteración 141000: Log-verosimilitud = -0.309168\n",
            "Iteración 141500: Log-verosimilitud = -0.309162\n",
            "Iteración 142000: Log-verosimilitud = -0.309156\n",
            "Iteración 142500: Log-verosimilitud = -0.309150\n",
            "Iteración 143000: Log-verosimilitud = -0.309145\n",
            "Iteración 143500: Log-verosimilitud = -0.309139\n",
            "Iteración 144000: Log-verosimilitud = -0.309133\n",
            "Iteración 144500: Log-verosimilitud = -0.309127\n",
            "Iteración 145000: Log-verosimilitud = -0.309121\n",
            "Iteración 145500: Log-verosimilitud = -0.309116\n",
            "Iteración 146000: Log-verosimilitud = -0.309110\n",
            "Iteración 146500: Log-verosimilitud = -0.309104\n",
            "Iteración 147000: Log-verosimilitud = -0.309099\n",
            "Iteración 147500: Log-verosimilitud = -0.309093\n",
            "Iteración 148000: Log-verosimilitud = -0.309087\n",
            "Iteración 148500: Log-verosimilitud = -0.309082\n",
            "Iteración 149000: Log-verosimilitud = -0.309076\n",
            "Iteración 149500: Log-verosimilitud = -0.309071\n",
            "Iteración 150000: Log-verosimilitud = -0.309065\n",
            "Iteración 150500: Log-verosimilitud = -0.309060\n",
            "Iteración 151000: Log-verosimilitud = -0.309054\n",
            "Iteración 151500: Log-verosimilitud = -0.309049\n",
            "Iteración 152000: Log-verosimilitud = -0.309043\n",
            "Iteración 152500: Log-verosimilitud = -0.309038\n",
            "Iteración 153000: Log-verosimilitud = -0.309032\n",
            "Iteración 153500: Log-verosimilitud = -0.309027\n",
            "Iteración 154000: Log-verosimilitud = -0.309021\n",
            "Iteración 154500: Log-verosimilitud = -0.309016\n",
            "Iteración 155000: Log-verosimilitud = -0.309011\n",
            "Iteración 155500: Log-verosimilitud = -0.309005\n",
            "Iteración 156000: Log-verosimilitud = -0.309000\n",
            "Iteración 156500: Log-verosimilitud = -0.308995\n",
            "Iteración 157000: Log-verosimilitud = -0.308989\n",
            "Iteración 157500: Log-verosimilitud = -0.308984\n",
            "Iteración 158000: Log-verosimilitud = -0.308979\n",
            "Iteración 158500: Log-verosimilitud = -0.308973\n",
            "Iteración 159000: Log-verosimilitud = -0.308968\n",
            "Iteración 159500: Log-verosimilitud = -0.308963\n",
            "Iteración 160000: Log-verosimilitud = -0.308958\n",
            "Iteración 160500: Log-verosimilitud = -0.308952\n",
            "Iteración 161000: Log-verosimilitud = -0.308947\n",
            "Iteración 161500: Log-verosimilitud = -0.308942\n",
            "Iteración 162000: Log-verosimilitud = -0.308937\n",
            "Iteración 162500: Log-verosimilitud = -0.308932\n",
            "Iteración 163000: Log-verosimilitud = -0.308927\n",
            "Iteración 163500: Log-verosimilitud = -0.308922\n",
            "Iteración 164000: Log-verosimilitud = -0.308916\n",
            "Iteración 164500: Log-verosimilitud = -0.308911\n",
            "Iteración 165000: Log-verosimilitud = -0.308906\n",
            "Iteración 165500: Log-verosimilitud = -0.308901\n",
            "Iteración 166000: Log-verosimilitud = -0.308896\n",
            "Iteración 166500: Log-verosimilitud = -0.308891\n",
            "\n",
            "Coeficientes finales:\n",
            "[-0.29603212 -0.37773392  0.7125362   0.21037773 -0.9059339   0.2349421\n",
            " -0.96157996  0.66554785 -1.17539279 -0.78346324  0.04480519  1.61801873\n",
            " -0.16659217 -0.12943995 -0.85282862  0.90782178 -0.35102527 -0.50973325\n",
            "  0.21370113 -0.16775478  0.34975755 -0.47803488 -0.78831116  0.6969543\n",
            "  2.52385906  1.19045222 -0.33202045 -0.15488017  1.05578025]\n",
            "Número total de iteraciones: 166892\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 700x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   0\n",
            "Intercepto -1.309065\n",
            "age        -0.386715\n",
            "trestbps    0.716105\n",
            "chol        0.192867\n",
            "thalach    -0.919874\n",
            "oldpeak     0.204574\n",
            "sex_0      -1.478245\n",
            "sex_1       0.169181\n",
            "cp_1       -1.492980\n",
            "cp_2       -0.902298\n",
            "cp_3       -0.220775\n",
            "cp_4        1.306988\n",
            "fbs_0      -0.650637\n",
            "fbs_1      -0.658427\n",
            "restecg_0  -2.145467\n",
            "restecg_1   2.504097\n",
            "restecg_2  -1.667694\n",
            "exang_0    -1.010511\n",
            "exang_1    -0.298554\n",
            "slope_1    -0.533597\n",
            "slope_2     0.027751\n",
            "slope_3    -0.803219\n",
            "ca_0.0      2.089566\n",
            "ca_1.0      3.561698\n",
            "ca_2.0      5.487800\n",
            "ca_3.0      4.117644\n",
            "thal_3.0    1.234959\n",
            "thal_6.0    1.369863\n",
            "thal_7.0    2.642418\n"
          ]
        }
      ],
      "source": [
        "# Realizamos el entrenamiento y comparación visual de modelos con dos tasas de \n",
        "# aprendizaje distintas mediante descenso de gradiente\n",
        "lr_high = 0.1\n",
        "model_high = LogisticGradientDescent(lr_high, X_train, y_train)\n",
        "model_high.fit()\n",
        "\n",
        "lr_low = 0.01\n",
        "model_low = LogisticGradientDescent(lr_low, X_train, y_train)\n",
        "model_low.fit()\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "plt.plot(model_high.loss_history, label=f'LR = {lr_high}', color='blue', linewidth=2)\n",
        "plt.plot(model_low.loss_history, label=f'LR = {lr_low}', color='red', linewidth=2)\n",
        "plt.title('Convergencia del Log-Likelihood durante el entrenamiento')\n",
        "plt.xlabel('Número de iteraciones')\n",
        "plt.ylabel('Log-Verosimilitud media')\n",
        "plt.legend()\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Finalmente mostramos los  coeficientes del modelo con learning rate 0.1\n",
        "coef_df = pd.DataFrame(model_high.coefficients.reshape(1, -1), columns=X_train.columns)\n",
        "print(coef_df.T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlWhxwYaU4NM"
      },
      "source": [
        "3. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "BX6WUzNAU9jt"
      },
      "outputs": [],
      "source": [
        "def show_metric(my_metric):\n",
        "  return \"{:.2f}%\".format(my_metric * 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 86.81%\n",
            "precision: 92.68%\n",
            "recall: 80.85%\n",
            "F1 score: 86.36%\n",
            "matriz de confusion: \n",
            " [[41  3]\n",
            " [ 9 38]]\n"
          ]
        }
      ],
      "source": [
        "#Evaluamos el rendimiento del modelo de regresión logística implementado con \n",
        "#descenso de gradiente (learning rate = 0.01)\n",
        "def show_metric(my_metric):\n",
        "    return \"{:.2f}%\".format(my_metric * 100)\n",
        "\n",
        "y_pred_prob = predict_prob(X_test, model_low.coefficients)\n",
        "\n",
        "# Convertirmos probabilidades en clases (0 o 1)\n",
        "y_pred_class = (y_pred_prob >= 0.5).astype(int)\n",
        "\n",
        "print(\"accuracy: {}\".format(show_metric(accuracy_score(y_test, y_pred_class))))\n",
        "print(\"precision: {}\".format(show_metric(precision_score(y_test, y_pred_class))))\n",
        "print(\"recall: {}\".format(show_metric(recall_score(y_test, y_pred_class))))\n",
        "print(\"F1 score: {}\".format(show_metric(f1_score(y_test, y_pred_class))))\n",
        "print(\"matriz de confusion: \\n\", confusion_matrix(y_test, y_pred_class))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sklearn - Accuracy: 85.71%\n",
            "sklearn - Precision: 92.50%\n",
            "sklearn - Recall: 78.72%\n",
            "sklearn - F1 Score: 85.06%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "#Evaluamos el modelo de regresión logística de sklearn sin intercepto en el \n",
        "# conjunto de prueba\n",
        "model_sklearn = LogisticRegression(fit_intercept=False, max_iter=1000, solver='lbfgs')\n",
        "model_sklearn.fit(X_train, y_train)\n",
        "\n",
        "y_pred_sklearn = model_sklearn.predict(X_test)\n",
        "\n",
        "print(\"sklearn - Accuracy: {}\".format(show_metric(accuracy_score(y_test, y_pred_sklearn))))\n",
        "print(\"sklearn - Precision: {}\".format(show_metric(precision_score(y_test, y_pred_sklearn))))\n",
        "print(\"sklearn - Recall: {}\".format(show_metric(recall_score(y_test, y_pred_sklearn))))\n",
        "print(\"sklearn - F1 Score: {}\".format(show_metric(f1_score(y_test, y_pred_sklearn))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zInBohO0W60t"
      },
      "source": [
        "## Part B:\n",
        "#### Multiclass Logistic Regression via One-vs-All (OvA)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- B.4 Dataset (Wine) + escalado ---\n",
        "data = load_wine()\n",
        "Xw = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "yw = pd.Series(data.target, name=\"class\")\n",
        "\n",
        "_rs = RANDOM_STATE if \"RANDOM_STATE\" in globals() else 42\n",
        "Xw_train, Xw_test, yw_train, yw_test = train_test_split(\n",
        "    Xw, yw, test_size=0.30, stratify=yw, random_state=_rs\n",
        ")\n",
        "\n",
        "scaler_w = StandardScaler()\n",
        "Xw_train_s = scaler_w.fit_transform(Xw_train)\n",
        "Xw_test_s  = scaler_w.transform(Xw_test)\n",
        "\n",
        "def add_bias(A):\n",
        "    return np.c_[np.ones((A.shape[0], 1)), A]\n",
        "\n",
        "Xtr = add_bias(Xw_train_s)\n",
        "Xte = add_bias(Xw_test_s)\n",
        "classes = np.unique(yw_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OvA (scratch) — accuracy: 0.963\n",
            "Matriz de confusión (OvA scratch):\n",
            " [[18  0  0]\n",
            " [ 0 19  2]\n",
            " [ 0  0 15]]\n",
            "\n",
            "Reporte de clasificación (OvA scratch):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000        18\n",
            "           1     1.0000    0.9048    0.9500        21\n",
            "           2     0.8824    1.0000    0.9375        15\n",
            "\n",
            "    accuracy                         0.9630        54\n",
            "   macro avg     0.9608    0.9683    0.9625        54\n",
            "weighted avg     0.9673    0.9630    0.9632        54\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- B.5 OvA  ---\n",
        "\n",
        "def _ensure_funcs():\n",
        "    req = [\"sigmoid\", \"nll\", \"grad\", \"fit_gd\"]\n",
        "    return all(name in globals() for name in req)\n",
        "\n",
        "if not _ensure_funcs():\n",
        "    def sigmoid(z):\n",
        "        z = np.clip(z, -30, 30)\n",
        "        return 1.0 / (1.0 + np.exp(-z))\n",
        "    def nll(X, y, w, l2=0.0):\n",
        "        p = sigmoid(X @ w); eps = 1e-12\n",
        "        loss = -(y*np.log(p + eps) + (1 - y)*np.log(1 - p + eps)).mean()\n",
        "        if l2 > 0: loss += (l2/(2*X.shape[0])) * np.sum(w[1:]**2)\n",
        "        return loss\n",
        "    def grad(X, y, w, l2=0.0):\n",
        "        p = sigmoid(X @ w)\n",
        "        g = (X.T @ (p - y)) / X.shape[0]\n",
        "        if l2 > 0: g[1:] += (l2/X.shape[0]) * w[1:]\n",
        "        return g\n",
        "    def fit_gd(X, y, lr=5e-3, n_iter=2000, l2=0.0, log_every=10):\n",
        "        w = np.zeros(X.shape[1]); hist = []\n",
        "        for t in range(n_iter):\n",
        "            w -= lr * grad(X, y, w, l2)\n",
        "            if (t % log_every) == 0 or t == n_iter - 1:\n",
        "                hist.append(nll(X, y, w, l2))\n",
        "        return w, np.array(hist), log_every\n",
        "\n",
        "\n",
        "LR_OVA = 5e-3\n",
        "weights_ova, hist_ova = {}, {}\n",
        "for k in classes:\n",
        "    yk = (yw_train.to_numpy() == k).astype(int)\n",
        "    wk, hk, step = fit_gd(Xtr, yk, lr=LR_OVA, n_iter=2000, l2=0.0, log_every=10)\n",
        "    weights_ova[k] = wk\n",
        "    hist_ova[k] = hk\n",
        "\n",
        "\n",
        "probas = np.column_stack([1.0 / (1.0 + np.exp(-(Xte @ weights_ova[k]))) for k in classes])\n",
        "yhat_ova = classes[probas.argmax(axis=1)]\n",
        "\n",
        "\n",
        "acc_ova = accuracy_score(yw_test, yhat_ova)\n",
        "cm_ova  = confusion_matrix(yw_test, yhat_ova)\n",
        "print(\"OvA (scratch) — accuracy:\", round(acc_ova, 4))\n",
        "print(\"Matriz de confusión (OvA scratch):\\n\", cm_ova)\n",
        "try:\n",
        "    print(\"\\nReporte de clasificación (OvA scratch):\\n\",\n",
        "          classification_report(yw_test, yhat_ova, digits=4))\n",
        "except Exception:\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sklearn OvR — accuracy: 0.9815\n",
            "Matriz de confusión (sklearn OvR):\n",
            " [[18  0  0]\n",
            " [ 1 20  0]\n",
            " [ 0  0 15]]\n",
            "\n",
            "Reporte de clasificación (sklearn OvR):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9474    1.0000    0.9730        18\n",
            "           1     1.0000    0.9524    0.9756        21\n",
            "           2     1.0000    1.0000    1.0000        15\n",
            "\n",
            "    accuracy                         0.9815        54\n",
            "   macro avg     0.9825    0.9841    0.9829        54\n",
            "weighted avg     0.9825    0.9815    0.9815        54\n",
            "\n",
            "\n",
            "Clase 0 — Top-5 |coef| (scratch vs sklearn):\n",
            "                   scratch  sklearn\n",
            "proline             0.9845   1.5710\n",
            "alcohol             0.8056   1.2798\n",
            "bias               -0.7672  -1.7864\n",
            "alcalinity_of_ash  -0.7014  -1.3634\n",
            "flavanoids          0.6030   1.1154\n",
            "\n",
            "Clase 1 — Top-5 |coef| (scratch vs sklearn):\n",
            "                 scratch  sklearn\n",
            "alcohol          -0.9946  -1.4811\n",
            "color_intensity  -0.8968  -1.4694\n",
            "proline          -0.8727  -1.5622\n",
            "ash              -0.5682  -1.1274\n",
            "hue               0.5112   0.9822\n",
            "\n",
            "Clase 2 — Top-5 |coef| (scratch vs sklearn):\n",
            "                              scratch  sklearn\n",
            "bias                          -1.0888  -3.5556\n",
            "color_intensity                0.7677   1.0703\n",
            "hue                           -0.6533  -1.1501\n",
            "flavanoids                    -0.6430  -1.3185\n",
            "od280/od315_of_diluted_wines  -0.6382  -0.8706\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>OvA (scratch)</th>\n",
              "      <td>0.9630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sklearn OvR</th>\n",
              "      <td>0.9815</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               accuracy\n",
              "OvA (scratch)    0.9630\n",
              "sklearn OvR      0.9815"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- B.6 Comparación con sklearn (OvR) + coeficientes ---\n",
        "\n",
        "from sklearn.multiclass import OneVsRestClassifier  # evita warning deprecado\n",
        "\n",
        "base_lr = LogisticRegression(solver=\"lbfgs\", max_iter=5000, C=1.0, random_state=_rs)\n",
        "sk_ova = OneVsRestClassifier(base_lr)\n",
        "sk_ova.fit(Xw_train_s, yw_train)\n",
        "yhat_sk = sk_ova.predict(Xw_test_s)\n",
        "\n",
        "acc_sk = accuracy_score(yw_test, yhat_sk)\n",
        "cm_sk  = confusion_matrix(yw_test, yhat_sk)\n",
        "print(\"sklearn OvR — accuracy:\", round(acc_sk, 4))\n",
        "print(\"Matriz de confusión (sklearn OvR):\\n\", cm_sk)\n",
        "try:\n",
        "    print(\"\\nReporte de clasificación (sklearn OvR):\\n\",\n",
        "          classification_report(yw_test, yhat_sk, digits=4))\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "feat = [\"bias\"] + list(data.feature_names)\n",
        "\n",
        "coef_scr = {k: pd.Series(weights_ova[k], index=feat) for k in classes}\n",
        "\n",
        "coef_sk = {}\n",
        "for i, k in enumerate(classes):\n",
        "    est = sk_ova.estimators_[i]       \n",
        "    w_k = np.r_[est.intercept_[0], est.coef_[0]]\n",
        "    coef_sk[k] = pd.Series(w_k, index=feat)\n",
        "\n",
        "for k in classes:\n",
        "    top = coef_scr[k].abs().sort_values(ascending=False).head(5).index\n",
        "    tabla = pd.DataFrame({\"scratch\": coef_scr[k].loc[top],\n",
        "                          \"sklearn\": coef_sk[k].loc[top]}).round(4)\n",
        "    print(f\"\\nClase {k} — Top-5 |coef| (scratch vs sklearn):\")\n",
        "    print(tabla)\n",
        "\n",
        "# (Opcional) Resumen de accuracies en una tablita\n",
        "pd.DataFrame({\"accuracy\": [acc_ova, acc_sk]},\n",
        "             index=[\"OvA (scratch)\", \"sklearn OvR\"]).round(4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqlPsRg4XDWA"
      },
      "source": [
        "## PARTE: C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Derivación del Gradiente — Verosimilitud Logarítmica Multiclase\n",
        "\n",
        "Para un modelo con parámetros :\n",
        "\n",
        "$$\n",
        "L(\\theta) = \\prod_{i=1}^n \n",
        "\\frac{\\exp(\\theta_{y^{(i)}}^\\top x^{(i)})}\n",
        "{\\sum_{l=1}^K \\exp(\\theta_l^\\top x^{(i)})}.\n",
        "$$\n",
        "\n",
        "Tomando logaritmos:\n",
        "\n",
        "$$\n",
        "\\ell(\\theta) = \\sum_{i=1}^n \n",
        "\\Big[\n",
        "\\theta_{y^{(i)}}^\\top x^{(i)} -\n",
        "\\log\\!\\left(\\sum_{j=1}^K e^{\\theta_j^\\top x^{(i)}}\\right)\n",
        "\\Big].\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Derivada con respecto a la clase \\( m \\)\n",
        "\n",
        "**1. Primer término**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\theta_m}(\\theta_{y^{(i)}}^\\top x^{(i)}) \n",
        "= \\mathbb{1}\\{y^{(i)} = m\\}\\, x^{(i)}.\n",
        "$$\n",
        "\n",
        "**2. Segundo término**\n",
        "\n",
        "$$\n",
        "\\frac{\\partial}{\\partial \\theta_m}\n",
        "\\Big[-\\log\\!\\big(\\sum_{j=1}^K e^{\\theta_j^\\top x^{(i)}}\\big)\\Big]\n",
        "= -\\frac{e^{\\theta_m^\\top x^{(i)}}}{\\sum_{j=1}^K e^{\\theta_j^\\top x^{(i)}}}\n",
        "\\, x^{(i)} = -p_{im}x^{(i)}.\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Combinando ambos términos\n",
        "\n",
        "$$\n",
        "\\frac{\\partial \\ell(\\theta)}{\\partial \\theta_m}\n",
        "= \\sum_{i=1}^n \n",
        "\\big(\\mathbb{1}\\{y^{(i)} = m\\} - p_{im}\\big)x^{(i)}.\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Gradiente final\n",
        "\n",
        "$$\n",
        "\\boxed{\n",
        "\\nabla_{\\theta_m}\\ell(\\theta)\n",
        "= \\sum_{i=1}^n \n",
        "\\left(\\mathbb{1}\\{y^{(i)} = m\\} - p_{im}\\right)x^{(i)}\n",
        "}\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = load_wine()\n",
        "XC = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "yC = pd.Series(data.target, name=\"class\")\n",
        "\n",
        "_rs = RANDOM_STATE if \"RANDOM_STATE\" in globals() else 42\n",
        "XC_train, XC_test, yC_train, yC_test = train_test_split(\n",
        "    XC, yC, test_size=0.30, stratify=yC, random_state=_rs\n",
        ")\n",
        "\n",
        "scalerC = StandardScaler()\n",
        "XC_train_s = scalerC.fit_transform(XC_train)\n",
        "XC_test_s  = scalerC.transform(XC_test)\n",
        "\n",
        "def add_bias(A):\n",
        "    return np.c_[np.ones((A.shape[0], 1)), A]\n",
        "\n",
        "XtrC = add_bias(XC_train_s)\n",
        "XteC = add_bias(XC_test_s)\n",
        "\n",
        "classesC = np.unique(yC_train)                   \n",
        "K = len(classesC)\n",
        "d1 = XtrC.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- C.3 Softmax multinomial ---\n",
        "\n",
        "index_of = {c:i for i,c in enumerate(classesC)}\n",
        "ytr_idx = np.vectorize(index_of.get)(yC_train.to_numpy())\n",
        "yte_idx = np.vectorize(index_of.get)(yC_test.to_numpy())\n",
        "\n",
        "def one_hot(y_idx, K):\n",
        "    Y = np.zeros((y_idx.shape[0], K))\n",
        "    Y[np.arange(y_idx.shape[0]), y_idx] = 1.0\n",
        "    return Y\n",
        "\n",
        "Ytr_one = one_hot(ytr_idx, K)\n",
        "\n",
        "def softmax_stable(Z):\n",
        "    Z = Z - Z.max(axis=1, keepdims=True)       \n",
        "    np.exp(Z, out=Z)                           \n",
        "    Z /= Z.sum(axis=1, keepdims=True)\n",
        "    return Z\n",
        "\n",
        "def nll_multiclass(X, Y_one, W, l2=0.0):\n",
        "    P = softmax_stable(X @ W.T)\n",
        "    eps = 1e-12\n",
        "    loss = -(Y_one * np.log(P + eps)).sum(axis=1).mean()\n",
        "    if l2 > 0:\n",
        "        loss += (l2/(2*X.shape[0])) * np.sum(W[:,1:]**2)\n",
        "    return loss\n",
        "\n",
        "def grad_W(X, Y_one, W, l2=0.0):\n",
        "    P = softmax_stable(X @ W.T)\n",
        "    G = ((P - Y_one).T @ X) / X.shape[0]       \n",
        "    if l2 > 0:\n",
        "        G[:,1:] += (l2/X.shape[0]) * W[:,1:]\n",
        "    return G\n",
        "\n",
        "def fit_gd_softmax(X, Y_one, lr=5e-3, n_iter=2000, l2=0.0, log_every=10):\n",
        "    W = np.zeros((K, d1))\n",
        "    hist = []\n",
        "    for t in range(n_iter):\n",
        "        W -= lr * grad_W(X, Y_one, W, l2)\n",
        "        if (t % log_every) == 0 or t == n_iter - 1:\n",
        "            hist.append(nll_multiclass(X, Y_one, W, l2))\n",
        "    return W, np.array(hist), log_every\n",
        "\n",
        "def predict_proba_softmax(X, W):\n",
        "    return softmax_stable(X @ W.T)\n",
        "\n",
        "def predict_label_softmax(X, W):\n",
        "    return predict_proba_softmax(X, W).argmax(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- C.4 Entrenar con dos learning rates y graficar convergencia ---\n",
        "lrsC = [1e-2, 5e-3]     \n",
        "histC = {}\n",
        "WC = {}\n",
        "\n",
        "plt.figure(figsize=(6,4))\n",
        "for lr in lrsC:\n",
        "    Wlr, Hlr, step = fit_gd_softmax(XtrC, Ytr_one, lr=lr, n_iter=2000, l2=0.0, log_every=10)\n",
        "    WC[lr] = Wlr\n",
        "    histC[lr] = Hlr\n",
        "    it_axis = np.arange(len(Hlr)) * step\n",
        "    plt.plot(it_axis, Hlr, label=f\"lr={lr}\")\n",
        "plt.xlabel(\"Iteraciones\"); plt.ylabel(\"NLL (train)\")\n",
        "plt.title(\"Convergencia — Softmax (desde cero)\")\n",
        "plt.legend(); plt.show()\n",
        "\n",
        "best_lrC = min(lrsC, key=lambda a: histC[a][-1])\n",
        "W_best = WC[best_lrC]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Softmax (scratch) — accuracy: 0.9815\n",
            "Matriz de confusión (Softmax scratch):\n",
            " [[18  0  0]\n",
            " [ 0 20  1]\n",
            " [ 0  0 15]]\n",
            "\n",
            "Reporte de clasificación (Softmax scratch):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    1.0000    1.0000        18\n",
            "           1     1.0000    0.9524    0.9756        21\n",
            "           2     0.9375    1.0000    0.9677        15\n",
            "\n",
            "    accuracy                         0.9815        54\n",
            "   macro avg     0.9792    0.9841    0.9811        54\n",
            "weighted avg     0.9826    0.9815    0.9816        54\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- C.5 Evaluación del modelo softmax scratch ---\n",
        "yhat_idx = predict_label_softmax(XteC, W_best)\n",
        "yhat_softmax = classesC[yhat_idx]                 \n",
        "\n",
        "acc_soft = accuracy_score(yC_test, yhat_softmax)\n",
        "cm_soft  = confusion_matrix(yC_test, yhat_softmax)\n",
        "print(\"Softmax (scratch) — accuracy:\", round(acc_soft, 4))\n",
        "print(\"Matriz de confusión (Softmax scratch):\\n\", cm_soft)\n",
        "print(\"\\nReporte de clasificación (Softmax scratch):\\n\",\n",
        "      classification_report(yC_test, yhat_softmax, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "sklearn multinomial — accuracy: 0.9815\n",
            "Matriz de confusión (sklearn multinomial):\n",
            " [[18  0  0]\n",
            " [ 1 20  0]\n",
            " [ 0  0 15]]\n",
            "\n",
            "Reporte de clasificación (sklearn multinomial):\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9474    1.0000    0.9730        18\n",
            "           1     1.0000    0.9524    0.9756        21\n",
            "           2     1.0000    1.0000    1.0000        15\n",
            "\n",
            "    accuracy                         0.9815        54\n",
            "   macro avg     0.9825    0.9841    0.9829        54\n",
            "weighted avg     0.9825    0.9815    0.9815        54\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- C.6 Comparación con sklearn (multinomial) ---\n",
        "sk_multi = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\",\n",
        "                              max_iter=5000, C=1.0, random_state=_rs)\n",
        "sk_multi.fit(XC_train_s, yC_train)\n",
        "yhat_sk_mul = sk_multi.predict(XC_test_s)\n",
        "\n",
        "acc_sk_mul = accuracy_score(yC_test, yhat_sk_mul)\n",
        "cm_sk_mul  = confusion_matrix(yC_test, yhat_sk_mul)\n",
        "print(\"\\nsklearn multinomial — accuracy:\", round(acc_sk_mul, 4))\n",
        "print(\"Matriz de confusión (sklearn multinomial):\\n\", cm_sk_mul)\n",
        "print(\"\\nReporte de clasificación (sklearn multinomial):\\n\",\n",
        "      classification_report(yC_test, yhat_sk_mul, digits=4))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
